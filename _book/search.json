[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ENVS-Book",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "narrative_markdown.html",
    "href": "narrative_markdown.html",
    "title": "2  Markdown",
    "section": "",
    "text": "2.1 Impetus\nIn current data analytics and communication, there are a wide variety of platforms on which we can provide summaries and insights regarding our work. Each of these end points requires a non-insignificant amount of effort to learn these systems. Moreover, they all are cul de sacs in that all the effort you exert to learn one will not allow you to get the benefits of any other platform than the one you just learned.\nEnter Pandoc, the universal document converter. Some really smart programmers have put together a set of software that allows you to convert from or two (and hence between) different document types given that most documents are regularly structured. With Pandoc, it does not matter if you do or do not have Word or PowerPoint or EPub or LaTeX or whatever, as long as you can create one of the supported types, you can convert that input into a huge variety of output types.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Markdown</span>"
    ]
  },
  {
    "objectID": "narrative_markdown.html#impetus",
    "href": "narrative_markdown.html#impetus",
    "title": "2  Markdown",
    "section": "",
    "text": "This is stupid. - R. Dyer",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Markdown</span>"
    ]
  },
  {
    "objectID": "narrative_markdown.html#pandoc-supported-conversions",
    "href": "narrative_markdown.html#pandoc-supported-conversions",
    "title": "2  Markdown",
    "section": "2.2 Pandoc Supported Conversions",
    "text": "2.2 Pandoc Supported Conversions\n\n\n\nConversion Formats\n\n\nThis is critical for us because Code is just text. Once it is evaluated, it can replaced with:\n\nNumerical values from one or more calculations,\nTextual content from analyses or manipulation, or\nGraphical content from plots.\n\nAs such, we can embed R code within raw text to create our analyses and documents.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Markdown</span>"
    ]
  },
  {
    "objectID": "narrative_markdown.html#installing-quarto-for-markdown",
    "href": "narrative_markdown.html#installing-quarto-for-markdown",
    "title": "2  Markdown",
    "section": "2.3 Installing Quarto for Markdown",
    "text": "2.3 Installing Quarto for Markdown\nThe first step is to go to quarto and download the quarto engine for your particular laptop.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Markdown</span>"
    ]
  },
  {
    "objectID": "narrative_markdown.html#markdown-syntax",
    "href": "narrative_markdown.html#markdown-syntax",
    "title": "2  Markdown",
    "section": "2.4 Markdown Syntax",
    "text": "2.4 Markdown Syntax\nFor maximum usability, the document that we embed our code into should be as widely available as possible—unhindered by the necessity of having a particular program just to view the content. For this, R uses Markdown, created by John Gruber & Aaron Swartz in 2004. Markdown was created so that people are enabled “…to write using an easy-to-read and easy-to-write plain text format…”\nBecause everything is text, it is easy share and collaborate using Markdown, and for R, it is how we can make a wide array of output document types including (but not limited to):\n\nConventional documents (PDF, Word, RTF, etc.)\nHTML pages with interactive elements (this document here is an interactive html document).\nPresentations (LaTeX, PowerPoint, JavaScript, etc.)\nDashboards with interactive content.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Markdown</span>"
    ]
  },
  {
    "objectID": "narrative_markdown.html#text-markup",
    "href": "narrative_markdown.html#text-markup",
    "title": "2  Markdown",
    "section": "2.5 Text Markup",
    "text": "2.5 Text Markup\nWhen we make a document, presentation, or any other output, there are only a finite set of different text components we can put into the document. The document itself does not need to be heavy or bloated, it is just text (though surprisingly, a blank Word document on my laptop with nothing in the document itself is still 12KB in size!). Common elements include:\n\nHeaders & Titles\nTypography such as italic, bold, underline, strike through\nLists (numbered or as bullets)\nPictures and links\nPage numbers, tables of contents, etc.\n\nWhat Markdown does is allows you to type these components and use ‘marking’ around the elements to make them different from regular text. It is really, amazingly simple.\nTitle and headers are created by prepending a hashtag\n# Header 1\n## Header 2\n### Header 3\n#### Header 4\nare knit into the proper header styles.\nThe actual appearance of the headers are determined by where it is being presented (e.g., in Word it will take the default typography and font attributes, etc.).\nIn text markdown examples are shown below and are contained within paragraphs of text. Individual paragraphs are delimited by either a blank line between them or two spaces at the end of the sentence.\n\n\n\nMarkdown\nRendered As\n\n\n\n\nplain text\nplain text\n\n\n*italic*\nitalic\n\n\n**bold**\nbold\n\n\n~~strike through~~\nstrike through\n\n\n\nYou can also embed links and images. Both of these are configured in two parts. For links, you need to specify the text that can be clicked upon and it must be surrounded in square brackets. The link to the web or file or image is right next to the square brackets and is contained within parentheses. The difference between link and image is that images have alternative text (or at times captions) and the whole thing has an exclamation mark in front of it. Here are some examples.\n\n\n\nMarkdown\nRendered As\n\n\n\n\n[SLSS](https://slss.vcu.edu)\nSLSS\n\n\n![Goat](https://live.staticflickr.com/2417/2278662416_7683abd2d4_n_d.jpg)\n\n\n\n\nLists (both numbered and unordered) are created using dashes or asterisks.\n\nBullet 1\n\nBullet 2\n\nBullet 3\n\nWill be turned into an unordered list as:\n\nBullet 1\n\nBullet 2\n\nBullet 3\n\nWhereas the following raw text.1\n1. First\n1. Second\n1. Third\nWill be rendered in list format as:\n\nFirst\n\nSecond\n\nThird\n\nActually, you can just use 1. in front of every line if you like, it will auto-number them for you when it makes a list. I tend to do this because it makes it a bit easier in case I want to reorder the list later and I don’t have to go back and change the numbers.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Markdown</span>"
    ]
  },
  {
    "objectID": "narrative_markdown.html#code-text",
    "href": "narrative_markdown.html#code-text",
    "title": "2  Markdown",
    "section": "2.6 Code & Text",
    "text": "2.6 Code & Text\nOn of the strengths of RMarkdown is the ability to mix code and text together in one place. This allows us to bring all of our analyses and data as close to one another as possible, helping with reproducibility and error reduction.\n\n2.6.1 Inline Code\nYou can easily integrate code, into the text, either to be displayed OR to be evaluated. For example, in R you get the value of \\(\\pi\\) by the constant pi. Type that into the console and it will return 3.1415927.\nIf you look at the RMarkdown for that paragraph above, it looks like the following before knitting:\nYou can easily integrate code, into the text, either to be displayed *OR* to be evaluated.  For example, in `R` you get the value of $\\pi$ by the constant `pi`. Type that into the console and it will return 3.1415927.\nNotice the following parts:\n\nSymbols: The \\(\\pi\\) symbol is created by the name of the symbol surrounded by dollar signs. $ $. There are a ton of symbols and equations you can use, all borrowed from LaTeX, so if you need complicated equations or symbols, this is not a problem.\nText rendered as code (in typography) but not evaluated: Both the `R` and the `pi` are examples here. Nothing is evaluated, but it looks like code.\nEvaluated R Code: Any code between \\rand`will be evaluated as R code within the text. When you knit the document, it will be run and the contents between the`rand`are replaced by the output of theRcode. The example here was \\pi` at the end of the last sentence.\n\n\n\n2.6.2 Code Chunks\nIn addition to code within the text, RMarkdown supports code chunks, which can be one or many lines of raw R code. This code is executed and the results are merged into the markdown in the document (text, graphical, interactive widgets, whatever) before knitting.\nEach chunk is enclosed within boundary rows, the top row must contain three acute accents (back ticks - `) followed by the letter r in curly brackets ```{r}. The end of the chunk is indicated by three back ticks on their own line such as ```. Everything between these two enclosing lines is treated as R code and is subject to evaluation when you re-knit the document.\nHere is what a chunk looks like in markdown that prints out a simple message “This is text from a chunk.\n```{r}\nprint(“This is text from a chunk”)\n```\nWhen it is evaluated, the R interpreter removes the first and last rows, and executes the code within them. By default, the code is presented as a box in the output as well as any output that is produced from the code.\n\nprint(\"This is text from a chunk\")\n\n[1] \"This is text from a chunk\"\n\n\nThe first line in the chunk can also be used to modify the behavior of the code. There are several options that you can place within the curly brackets, including:\n\n{r eval=FALSE}: Will not evaluate (e.g., run) the code. The default value is TRUE.\n\n{r echo=FALSE}: Will not show the code in the document. This is great for our final version of our analyses, we want the output but not the code chunks showing. The default value is TRUE.\n\n{r message=FALSE, warning=FALSE, error=FALSE}: These suppress the messages that R prints out on occasion.\n\nSee the reference guide for several more options you can put into the header of each chunk.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Markdown</span>"
    ]
  },
  {
    "objectID": "narrative_markdown.html#code-chunks-in-document",
    "href": "narrative_markdown.html#code-chunks-in-document",
    "title": "2  Markdown",
    "section": "2.7 Code Chunks in Document",
    "text": "2.7 Code Chunks in Document\nThere are some very fundamental issues regarding chunks, the R environment, and documents that should be pointed out here.\n\nThe R environment (see tab labeled Environment in the RStudio interface) has all the variables and new functions that you have created listed and available for use.\nAn R Markdown document is not a ‘living’ environment. If you make a change in a chunk, you must rerun that chunk to have the output available and inserted into the Environment. It does not do it automagically.\nWhen you knit a document, the only data it has is what is actually in the document itself. It does not look to the general Environment for variables and functions. This means that if you create a variable or load data using the Console and then reference it in the Document, it will fail when you try to knit the document.\nAll the code and variables in a document (if they are not within a chunk with eval=FALSE) is visible to everything in the document below where it was defined.\n\nChunks are evaluated from the top of the document to the bottom of the document.\n\nThe options for each chunk are available from the setup menu on the top right of the chunk itself (the gear icon). Additional options include a button to run all the chunks prior to this one as well as running this particular chunk (see image).\n\n\n\n\nOption buttons for each chunk include a quick menu for optoins (gear), the ability to run all the chunks above this one (triangle and line button in the middle), and run this particular chunk (play button).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Markdown</span>"
    ]
  },
  {
    "objectID": "narrative_markdown.html#footnotes",
    "href": "narrative_markdown.html#footnotes",
    "title": "2  Markdown",
    "section": "",
    "text": "This is a footnote and is defined by enclosing square brackets and a carat symbol (^) where you want to put the footnote in the text (e.g., [^1]) and then at the bottom of the document add the text (this part) prepended by [^1]:. The linking to the footnote and back to the place you put it will be automagically inserted.↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Markdown</span>"
    ]
  },
  {
    "objectID": "narrative_datatypes.html",
    "href": "narrative_datatypes.html",
    "title": "3  Data Types",
    "section": "",
    "text": "3.1 Missing Data\nThe most fundamental type of data in R is data that does not exist! Missing data! It is represented as NA\nx &lt;- NA",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Types</span>"
    ]
  },
  {
    "objectID": "narrative_datatypes.html#missing-data",
    "href": "narrative_datatypes.html#missing-data",
    "title": "3  Data Types",
    "section": "",
    "text": "The Absence of Data",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Types</span>"
    ]
  },
  {
    "objectID": "narrative_datatypes.html#numerical-data",
    "href": "narrative_datatypes.html#numerical-data",
    "title": "3  Data Types",
    "section": "3.2 Numerical Data",
    "text": "3.2 Numerical Data\n\nNumerical data contains all numerical represenations.\n\nBy far, the most common kind of data we use in our analyses is numerical data. This may represent measured things like height, snout-vent length (whatever that is), depth, age, etc. In data analysis, we commonly take (or obtain) measurements from several items and then try to characterize them using summaries and visualization.\nIn R, the numerical data type can be defined as:\n\nX &lt;- 42\n\nNotice how the numerical value of 42 is assigned to the variable named X. To have R print out the value of a particular variable, you can type its name in the console and it will give it to you.\n\nX\n\n[1] 42\n\n\n\n3.2.1 Operators\nNumeric types have a ton of normal operators that can be used. Some examples include:\nThe usual arithmetic operators:\n\nx &lt;- 10\ny &lt;- 23\n\nx + y\n\n[1] 33\n\nx - y\n\n[1] -13\n\nx * y\n\n[1] 230\n\nx / y\n\n[1] 0.4347826\n\n\nYou have the exponential:\n\n## x raised to the y\nx^y\n\n[1] 1e+23\n\n## the inverse of an exponent is a root, here is the 23rd root of 10\nx^(1/y)\n\n[1] 1.105295\n\n\nThe logarithmic:\n\n## the natural log\nlog(x)\n\n[1] 2.302585\n\n## Base 10 log\nlog(x,base=10)\n\n[1] 1\n\n\nAnd the modulus operator:\n\ny %% x\n\n[1] 3\n\n\nIf you didn’t know what this one is, don’t worry. The modulus is just the remainder after division like you did in grade school. The above code means that 23 divided by 10 has a remainder of 3. I include it here just to highlight the fact that many of the operators that we will be working with in R are created by more than just a single symbol residing at the top row of your computer keyboard. There are just too few symbos on the normal keyboard to represent the breath of operators. The authors of R have decided that using combinations of symbols to handle these and you will get used to them in not time at all.\n\n\n3.2.2 Introspection & Coercion\nThe class() of a numeric type is (wait for it)… numeric (those R programmers are sure clever).\n\nclass( 42 )\n\n[1] \"numeric\"\n\n\n\nIn this case class is the name of the function and there are one or more things we pass to that function. These must be enclosed in the parenthesis associated with class. The parantheses must be right next to the name of the function. If you put a space betwen the word class and the parentheses, it may not work the way you would like it to. You’ve been warned.\nThe stuff inside the parenthesis are called arguments and are the data that we pass to the function itself. In this case we pass a value or varible to the class function and it does its magic and tells us what kind of data type it is. Many functions have several arguements that can be passed to them, some optional, some not. We will get more into that on the lecture covering Functions.\n\nIt is also possible to inquire if a particular variable is of a certain class. This is done by using the is.* set of functions.\n\nis.numeric( 42 )\n\n[1] TRUE\n\nis.numeric( \"dr dyer\" )\n\n[1] FALSE\n\n\nSometimes we may need to turn one kind of class into another kind. Consider the following:\n\nx &lt;- \"42\"\nis.numeric( x )\n\n[1] FALSE\n\nclass(x)\n\n[1] \"character\"\n\n\nIt is a character data type because it is enclosed within a set of quotes. However, we can coerce it into a numeric type by:\n\ny &lt;- as.numeric( x )\nis.numeric( y )\n\n[1] TRUE\n\ny\n\n[1] 42",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Types</span>"
    ]
  },
  {
    "objectID": "narrative_datatypes.html#character-data",
    "href": "narrative_datatypes.html#character-data",
    "title": "3  Data Types",
    "section": "3.3 Character Data",
    "text": "3.3 Character Data\n\nCharacter data represents textual content.\n\nThe data type character is intended to represent textual data such as actual texts, names of objects, and other contnet that is intended to help both you and the audience you are trying to reach better understand your data.\n\nname &lt;- \"Dyer\"\nsport &lt;- \"Frolf\"\n\nThe two variables above have a sequence of characters enclosed by a double quote. You can use a single quote instead, however the enclosing quoting characters must be the same (e.g., you cannot start with a single quote and end with a double).\n\n3.3.1 Lengths\nThe length of a string is a measure of how many varibles there are, not the number of characters within it. For example, the length of dyer is\n\nlength(name)\n\n[1] 1\n\n\nbecause it only has one character but the number of characters within it is:\n\nnchar(name)\n\n[1] 4\n\n\nLength is defined specifically on the number of elements in a vector, and technically the variable dyer is a vector of length one. If we concatinate them into a vector (go see the vector content)\n\nphrase &lt;- c( name, sport )\n\nwe find that it has a length of 2\n\nlength(phrase)\n\n[1] 2\n\n\nAnd if we ask the vector how many characters are in the elements it contains, it gives us a vector of numeric types representing the number of letters in each of the elements.\n\nnchar(phrase)\n\n[1] 4 5\n\n\n\n\n3.3.2 Putting Character Objects Together\nThe binary + operator has not been defined for objects of class character, which is understandable once we consider all the different ways we may want to put the values contained in the variables together. If you try it, R will complain.\n\nname + sport\n\nError in name + sport: non-numeric argument to binary operator\n\n\nThe paste() function is designed to take a collection of character variables and smush them togethers. By default, it inserts a space between each of the variables and/or values passed to it.\n\npaste( name, \"plays\", sport )\n\n[1] \"Dyer plays Frolf\"\n\n\nAlthough, you can have any kind of separator you like:\n\npaste(name, sport, sep=\" is no good at \")\n\n[1] \"Dyer is no good at Frolf\"\n\n\nThe elements you pass to paste() do not need to be held in variables, you can put quoted character values in there as well.\n\npaste( name, \" the \", sport, \"er\", sep=\"\") \n\n[1] \"Dyer the Frolfer\"\n\n\nIf you have a vector of character types, by default, it considers the pasting operation to be applied to every element of the vector.\n\npaste( phrase , \"!\")\n\n[1] \"Dyer !\"  \"Frolf !\"\n\n\nHowever if you intention is to take the elements of the vector and paste them together, then you need to specify that using the collapse optional argument. By default, it is set to NULL, and that state tells the function to apply the paste()-ing to each element. However, if you set collapse to something other than NULL, it will use that to take all the elements and put them into a single response.\n\npaste( phrase, collapse = \" is not good at \") \n\n[1] \"Dyer is not good at Frolf\"\n\n\n\n\n3.3.3 String Operations\nMany times, we need to extract components from within a longer character element. Here is a longer bit of text as an example.\n\ncorpus &lt;- \"An environmental impact statement (EIS), under United States environmental law, is a document required by the 1969 National Environmental Policy Act (NEPA) for certain actions 'significantly affecting the quality of the human environment'.[1] An EIS is a tool for decision making. It describes the positive and negative environmental effects of a proposed action, and it usually also lists one or more alternative actions that may be chosen instead of the action described in the EIS. Several U.S. state governments require that a document similar to an EIS be submitted to the state for certain actions. For example, in California, an Environmental Impact Report (EIR) must be submitted to the state for certain actions, as described in the California Environmental Quality Act (CEQA). One of the primary authors of the act is Lynton K. Caldwell.\"\n\n\n\n3.3.4 Splits\nWe can split the original string into several components by specifying which particular character or set of characters we wish to use to break it apart.\nAs we start working with increasingly more complicated string operations, I like to use a higher-level library (part of tidyverse) called stringr. If you do not have this library already installed, you can install it using install.packages(\"stringr\").\n\nlibrary( stringr )\n\nHere is an example using the space character to pull it apart into words.\n\nstr_split( corpus, pattern=\" \", simplify=TRUE)\n\n     [,1] [,2]            [,3]     [,4]        [,5]     [,6]    [,7]    \n[1,] \"An\" \"environmental\" \"impact\" \"statement\" \"(EIS),\" \"under\" \"United\"\n     [,8]     [,9]            [,10]  [,11] [,12] [,13]      [,14]      [,15]\n[1,] \"States\" \"environmental\" \"law,\" \"is\"  \"a\"   \"document\" \"required\" \"by\" \n     [,16] [,17]  [,18]      [,19]           [,20]    [,21] [,22]    [,23]\n[1,] \"the\" \"1969\" \"National\" \"Environmental\" \"Policy\" \"Act\" \"(NEPA)\" \"for\"\n     [,24]     [,25]     [,26]            [,27]       [,28] [,29]     [,30]\n[1,] \"certain\" \"actions\" \"'significantly\" \"affecting\" \"the\" \"quality\" \"of\" \n     [,31] [,32]   [,33]              [,34] [,35] [,36] [,37] [,38]  [,39]\n[1,] \"the\" \"human\" \"environment'.[1]\" \"An\"  \"EIS\" \"is\"  \"a\"   \"tool\" \"for\"\n     [,40]      [,41]     [,42] [,43]       [,44] [,45]      [,46] [,47]     \n[1,] \"decision\" \"making.\" \"It\"  \"describes\" \"the\" \"positive\" \"and\" \"negative\"\n     [,48]           [,49]     [,50] [,51] [,52]      [,53]     [,54] [,55]\n[1,] \"environmental\" \"effects\" \"of\"  \"a\"   \"proposed\" \"action,\" \"and\" \"it\" \n     [,56]     [,57]  [,58]   [,59] [,60] [,61]  [,62]         [,63]     [,64] \n[1,] \"usually\" \"also\" \"lists\" \"one\" \"or\"  \"more\" \"alternative\" \"actions\" \"that\"\n     [,65] [,66] [,67]    [,68]     [,69] [,70] [,71]    [,72]       [,73]\n[1,] \"may\" \"be\"  \"chosen\" \"instead\" \"of\"  \"the\" \"action\" \"described\" \"in\" \n     [,74] [,75]  [,76]     [,77]  [,78]   [,79]         [,80]     [,81]  [,82]\n[1,] \"the\" \"EIS.\" \"Several\" \"U.S.\" \"state\" \"governments\" \"require\" \"that\" \"a\"  \n     [,83]      [,84]     [,85] [,86] [,87] [,88] [,89]       [,90] [,91]\n[1,] \"document\" \"similar\" \"to\"  \"an\"  \"EIS\" \"be\"  \"submitted\" \"to\"  \"the\"\n     [,92]   [,93] [,94]     [,95]      [,96] [,97]      [,98] [,99]        \n[1,] \"state\" \"for\" \"certain\" \"actions.\" \"For\" \"example,\" \"in\"  \"California,\"\n     [,100] [,101]          [,102]   [,103]   [,104]  [,105] [,106] [,107]     \n[1,] \"an\"   \"Environmental\" \"Impact\" \"Report\" \"(EIR)\" \"must\" \"be\"   \"submitted\"\n     [,108] [,109] [,110]  [,111] [,112]    [,113]     [,114] [,115]     \n[1,] \"to\"   \"the\"  \"state\" \"for\"  \"certain\" \"actions,\" \"as\"   \"described\"\n     [,116] [,117] [,118]       [,119]          [,120]    [,121] [,122]   \n[1,] \"in\"   \"the\"  \"California\" \"Environmental\" \"Quality\" \"Act\"  \"(CEQA).\"\n     [,123] [,124] [,125] [,126]    [,127]    [,128] [,129] [,130] [,131]\n[1,] \"One\"  \"of\"   \"the\"  \"primary\" \"authors\" \"of\"   \"the\"  \"act\"  \"is\"  \n     [,132]   [,133] [,134]     \n[1,] \"Lynton\" \"K.\"   \"Caldwell.\"\n\n\nwhich shows 134 words in the text.\nI need to point out that I added the simplify=TRUE option to str_split. Had I not done that, it would have returned a list object that contained the individual vector of words. There are various reasons that it returns a list, none of which I can frankly understand, that is just the way the authors of the function made it.\n\n\n3.3.5 Substrings\nThere are two different things you may want to do with substrings; find them and replace them. Here are some ways to figure out where they are.\n\nstr_detect(corpus, \"Environment\")\n\n[1] TRUE\n\n\n\nstr_count( corpus, \"Environment\")\n\n[1] 3\n\n\n\nstr_locate_all( corpus, \"Environment\")\n\n[[1]]\n     start end\n[1,]   125 135\n[2,]   637 647\n[3,]   754 764\n\n\nWe can also replace instances of one substring with another.\n\nstr_replace_all(corpus, \"California\", \"Virginia\")\n\n[1] \"An environmental impact statement (EIS), under United States environmental law, is a document required by the 1969 National Environmental Policy Act (NEPA) for certain actions 'significantly affecting the quality of the human environment'.[1] An EIS is a tool for decision making. It describes the positive and negative environmental effects of a proposed action, and it usually also lists one or more alternative actions that may be chosen instead of the action described in the EIS. Several U.S. state governments require that a document similar to an EIS be submitted to the state for certain actions. For example, in Virginia, an Environmental Impact Report (EIR) must be submitted to the state for certain actions, as described in the Virginia Environmental Quality Act (CEQA). One of the primary authors of the act is Lynton K. Caldwell.\"\n\n\nThere is a lot more fun stuff to do with string based data.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Types</span>"
    ]
  },
  {
    "objectID": "narrative_datatypes.html#logical-data",
    "href": "narrative_datatypes.html#logical-data",
    "title": "3  Data Types",
    "section": "3.4 Logical Data",
    "text": "3.4 Logical Data\nLogical data consists of two mutually exclusive states: TRUE or FALSE\n \n\ndyer_has_good_jokes &lt;- TRUE\ndyer_has_good_jokes\n\n[1] TRUE\n\n\n\n3.4.1 Operators on Logical Types\nThere are 3 primary logical operators that can be used on logical types; one unary and two binary.\n \n\n3.4.1.1 Unary Operator\nThe negation operator\n\n!dyer_has_good_jokes\n\n[1] FALSE\n\n\n \n\n\n\n3.4.2 The Binary Operators\n\n3.4.2.1 The OR operator\n\nTRUE | FALSE\n\n[1] TRUE\n\n\n\n\n3.4.2.2 The AND operator\n\nTRUE & FALSE\n\n[1] FALSE\n\n\n\n\n\n3.4.3 Introspection\nLogical types have an introspection operator.\n \n\nis.logical( dyer_has_good_jokes )\n\n[1] TRUE\n\n\nCoercion of something else to a Logical is more case-specific.\nFrom character data.\n\nas.logical( \"TRUE\" )\n\n[1] TRUE\n\n\n \n\nas.logical( \"FALSE\" )\n\n[1] FALSE\n\n\nOther character types result in NA (missing data).\n\nas.logical( \"Bob\" )\n\n[1] NA\n\n\n\n\n3.4.4 Coercion\nCoercion of something else to a Logical is more case-specific.\n \nFrom numeric data:\n- Values of 0 are FALSE\n- Non-zero values are TRUE\n\nas.logical(0)\n\n[1] FALSE\n\n\n\nas.logical( 323 )\n\n[1] TRUE",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Types</span>"
    ]
  },
  {
    "objectID": "narrative_datatypes.html#dates",
    "href": "narrative_datatypes.html#dates",
    "title": "3  Data Types",
    "section": "3.5 Dates",
    "text": "3.5 Dates\n\nTime is the next dimension.\n\nThis topic covers the basics of how we put together data based upone date and time objects. For this, we will use the following data frame with a single column of data representing dates as they are written in the US.\nThese are several challenges associated with working with date and time objects. To those of us who are reading this with a background of how US time and date formats are read, we can easily interpret data objects as Month/Day/Year formats (e.g., “2/14/2018”), and is commonly represented in the kind of input data we work in R with as with a string of characters. Dates and times are sticky things in data analysis because they do not work the way we think they should. Here are some wrinkles:\n\nThere are many types of calendars, we use the Julian calendar. However, there are many other calendars that are in use that we may run into. Each of these calendars has a different starting year (e.g., in the Assyrian calendar it is year 6770, it is 4718 in the Chinese calendar, 2020 in the Gregorian, and 1442 in the Islamic calendar).\nWestern calendar has leap years (+1 day in February) as well as leap seconds because it is based on the rotation around the sun, others are based upon the lunar cycle and have other corrections.\nOn this planet, we have 24 different time zones. Some states (looking at you Arizona) don’t feel it necessary to follow the other states around so they may be the same as PST some of the year and the same as MST the rest of the year. The provence of Newfoundland decided to be half-way between time zones so they are GMT-2:30. Some states have more than one time zone even if they are not large in size (hello Indiana).\nDates and time are made up of odd units, 60-seconds a minute, 60-minutes an hour, 24-hours a day, 7-days a week, 2-weeks a fortnight, 28,29,30,or 31-days in a month, 365 or 366 days in a year, 100 years in a century, etc.\n\nFortunately, some smart programmers have figured this out for us already. What they did is made the second as the base unit of time and designated 00:00:00 on 1 January 1970 as the unix epoch. Time on most modern computers is measured from that starting point. It is much easier to measure the difference between two points in time using the seconds since unix epich and then translate it into one or more of these calendars than to deal with all the different calendars each time. So under the hood, much of the date and time issues are kept in terms of epoch seconds.\n\nunclass( Sys.time() )\n\n[1] 1764843173\n\n\n\n3.5.1 Basic Date Objects\nR has some basic date functionality built into it. One of the easiest says to get a date object created is to specify the a date as a character string and then coerce it into a data object. By default, this requires us to represent the date objects as “YEAR-MONTH-DAY” with padding 0 values for any integer of month or date below 9 (e.g., must be two-digits).\nSo for example, we can specify a date object as:\n\nclass_start &lt;- as.Date(\"2021-01-15\")\nclass_start\n\n[1] \"2021-01-15\"\n\n\nAnd it is of type:\n\nclass( class_start )\n\n[1] \"Date\"\n\n\nIf you want to make a the date from a different format, you need to specify what elements within the string representation using format codes. These codes (and many more) can be found by looking at ?strptime.\n\nclass_end &lt;- as.Date( \"5/10/21\", format = \"%m/%d/%y\")\nclass_end\n\n[1] \"2021-05-10\"\n\n\nI like to use some higher-level date functions from the lubridate library. If you don’t have it installed, do so using the normal approach.\n\nlibrary( lubridate )\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\nDate objects can be put into vectors and sequences just like other objects.\n\nsemester &lt;- seq( class_start, class_end, by = \"1 day\")\nsemester\n\n  [1] \"2021-01-15\" \"2021-01-16\" \"2021-01-17\" \"2021-01-18\" \"2021-01-19\"\n  [6] \"2021-01-20\" \"2021-01-21\" \"2021-01-22\" \"2021-01-23\" \"2021-01-24\"\n [11] \"2021-01-25\" \"2021-01-26\" \"2021-01-27\" \"2021-01-28\" \"2021-01-29\"\n [16] \"2021-01-30\" \"2021-01-31\" \"2021-02-01\" \"2021-02-02\" \"2021-02-03\"\n [21] \"2021-02-04\" \"2021-02-05\" \"2021-02-06\" \"2021-02-07\" \"2021-02-08\"\n [26] \"2021-02-09\" \"2021-02-10\" \"2021-02-11\" \"2021-02-12\" \"2021-02-13\"\n [31] \"2021-02-14\" \"2021-02-15\" \"2021-02-16\" \"2021-02-17\" \"2021-02-18\"\n [36] \"2021-02-19\" \"2021-02-20\" \"2021-02-21\" \"2021-02-22\" \"2021-02-23\"\n [41] \"2021-02-24\" \"2021-02-25\" \"2021-02-26\" \"2021-02-27\" \"2021-02-28\"\n [46] \"2021-03-01\" \"2021-03-02\" \"2021-03-03\" \"2021-03-04\" \"2021-03-05\"\n [51] \"2021-03-06\" \"2021-03-07\" \"2021-03-08\" \"2021-03-09\" \"2021-03-10\"\n [56] \"2021-03-11\" \"2021-03-12\" \"2021-03-13\" \"2021-03-14\" \"2021-03-15\"\n [61] \"2021-03-16\" \"2021-03-17\" \"2021-03-18\" \"2021-03-19\" \"2021-03-20\"\n [66] \"2021-03-21\" \"2021-03-22\" \"2021-03-23\" \"2021-03-24\" \"2021-03-25\"\n [71] \"2021-03-26\" \"2021-03-27\" \"2021-03-28\" \"2021-03-29\" \"2021-03-30\"\n [76] \"2021-03-31\" \"2021-04-01\" \"2021-04-02\" \"2021-04-03\" \"2021-04-04\"\n [81] \"2021-04-05\" \"2021-04-06\" \"2021-04-07\" \"2021-04-08\" \"2021-04-09\"\n [86] \"2021-04-10\" \"2021-04-11\" \"2021-04-12\" \"2021-04-13\" \"2021-04-14\"\n [91] \"2021-04-15\" \"2021-04-16\" \"2021-04-17\" \"2021-04-18\" \"2021-04-19\"\n [96] \"2021-04-20\" \"2021-04-21\" \"2021-04-22\" \"2021-04-23\" \"2021-04-24\"\n[101] \"2021-04-25\" \"2021-04-26\" \"2021-04-27\" \"2021-04-28\" \"2021-04-29\"\n[106] \"2021-04-30\" \"2021-05-01\" \"2021-05-02\" \"2021-05-03\" \"2021-05-04\"\n[111] \"2021-05-05\" \"2021-05-06\" \"2021-05-07\" \"2021-05-08\" \"2021-05-09\"\n[116] \"2021-05-10\"\n\n\nSome helpful functions include the Julian Ordinal Day (e.g., number of days since the start of the year).\n\nordinal_day &lt;- yday( semester[102] )\nordinal_day\n\n[1] 116\n\n\nThe weekday as an integer (0-6 starting on Sunday), which I use to index the named values.\n\ndays_of_week &lt;- c(\"Sunday\",\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\")\nx &lt;- wday( semester[32] )\ndays_of_week[ x ]\n\n[1] \"Monday\"\n\n\nSince we did not specify a time, things like hour() and minute() do not provide any usable information.\n\n\n3.5.2 Dates & Times\nTo add time to the date objects, we need to specify both date and time specifically. Here are some example data:\n\ndf &lt;- data.frame( Date = c(\"8/21/2004 7:33:51 AM\",\n                           \"7/12/2008 9:23:08 PM\",\n                           \"2/14/2010 8:18:30 AM\",\n                           \"12/23/2018 11:11:45 PM\",\n                           \"2/1/2019 4:42:00 PM\",\n                           \"5/17/2012 1:23:23 AM\",\n                           \"12/11/2020 9:48:02 PM\") )\nsummary( df )\n\n     Date          \n Length:7          \n Class :character  \n Mode  :character  \n\n\nJust like above, if we want to turn these into date and time objects we must be able to tell the parsing algorithm what elements are represented in each entry. There are many ways to make dates and time, 10/14 or 14 Oct or October 14 or Julian day 287, etc. These are designated by a format string were we indicate what element represents a day or month or year or hour or minute or second, etc. These are found by looking at the documentation for?strptime.\nIn our case, we have:\n- Month as 1 or 2 digits\n- Day as 1 or 2 digits\n- Year as 4 digits\n- a space to separate date from time\n- hour (not 24-hour though)\n- minutes in 2 digits\n- seconds in 2 digits\n- a space to separate time from timezone\n- timezone\n- / separating date objects\n- : separating time objects\nTo make the format string, we need to look up how to encode these items. The items in df for a date & time object such as 2/1/2019 4:42:00 PM have the format string:\n\nformat &lt;- \"%m/%d/%Y %I:%M:%S %p\"\n\nNow, we can convert the character string in the data frame to a date and time object.\n\n\n3.5.3 Lubridate\nInstead of using the built-in as.Date() functionality, I like the lubridate library1 as it has a lot of additional functionality that we’ll play with a bit later.\n\ndf$Date &lt;- parse_date_time( df$Date, \n                            orders=format, \n                            tz = \"EST\" )\nsummary( df )\n\n      Date                    \n Min.   :2004-08-21 07:33:51  \n 1st Qu.:2009-04-29 14:50:49  \n Median :2012-05-17 01:23:23  \n Mean   :2013-07-11 07:28:39  \n 3rd Qu.:2019-01-12 19:56:52  \n Max.   :2020-12-11 21:48:02  \n\nclass( df$Date )\n\n[1] \"POSIXct\" \"POSIXt\" \n\n\nNow, we can ask Date-like questions about the data such as what day of the week was the first sample taken?\n\nweekdays( df$Date[1] )\n\n[1] \"Saturday\"\n\n\nWhat is the range of dates?\n\nrange( df$Date )\n\n[1] \"2004-08-21 07:33:51 EST\" \"2020-12-11 21:48:02 EST\"\n\n\nWhat is the median of samples\n\nmedian( df$Date )\n\n[1] \"2012-05-17 01:23:23 EST\"\n\n\nand what julian ordinal day (e.g., how many days since start of the year) is the last record.\n\nyday( df$Date[4] )\n\n[1] 357\n\n\nJust for fun, I’ll add a column to the data that has weekday.\n\ndf$Weekday &lt;- weekdays( df$Date )\ndf\n\n                 Date  Weekday\n1 2004-08-21 07:33:51 Saturday\n2 2008-07-12 21:23:08 Saturday\n3 2010-02-14 08:18:30   Sunday\n4 2018-12-23 23:11:45   Sunday\n5 2019-02-01 16:42:00   Friday\n6 2012-05-17 01:23:23 Thursday\n7 2020-12-11 21:48:02   Friday\n\n\nHowever, we should probably turn it into a factor (e.g., a data type with pre-defined levels—and for us here—an intrinsic order of the levels).\n\ndf$Weekday &lt;- factor( df$Weekday, \n                        ordered = TRUE, \n                        levels = days_of_week\n                        )\nsummary( df$Weekday )\n\n   Sunday    Monday   Tuesday Wednesday  Thursday    Friday  Saturday \n        2         0         0         0         1         2         2 \n\n\n\n\n3.5.4 Filtering on Date Objects\nWe can easily filter the content within a data.frame using some helper functions such as hour(), minute(), weekday(), etc. Here are some examples including pulling out the weekends.\n\nweekends &lt;- df[ df$Weekday %in% c(\"Saturday\",\"Sunday\"), ]\nweekends\n\n                 Date  Weekday\n1 2004-08-21 07:33:51 Saturday\n2 2008-07-12 21:23:08 Saturday\n3 2010-02-14 08:18:30   Sunday\n4 2018-12-23 23:11:45   Sunday\n\n\nfinding items that are in the past (paste being defined as the last time this document was knit).\n\npast &lt;- df$Date[ df$Date &lt; Sys.time() ]\npast\n\n[1] \"2004-08-21 07:33:51 EST\" \"2008-07-12 21:23:08 EST\"\n[3] \"2010-02-14 08:18:30 EST\" \"2018-12-23 23:11:45 EST\"\n[5] \"2019-02-01 16:42:00 EST\" \"2012-05-17 01:23:23 EST\"\n[7] \"2020-12-11 21:48:02 EST\"\n\n\nItems that are during working hours\n\nwork &lt;- df$Date[ hour(df$Date) &gt;= 9 & hour(df$Date) &lt;= 17 ]\nwork\n\n[1] \"2019-02-01 16:42:00 EST\"\n\n\nAnd total range of values in days using normal arithmatic operations such as the minus operator.\n\nmax(df$Date) - min(df$Date)\n\nTime difference of 5956.593 days",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Types</span>"
    ]
  },
  {
    "objectID": "narrative_datatypes.html#questions",
    "href": "narrative_datatypes.html#questions",
    "title": "3  Data Types",
    "section": "3.6 Questions",
    "text": "3.6 Questions\nIf you have any questions for me specifically on this topic, please feel free to contact me directly or drop a post on the discussion board on Canvas.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Types</span>"
    ]
  },
  {
    "objectID": "narrative_datatypes.html#footnotes",
    "href": "narrative_datatypes.html#footnotes",
    "title": "3  Data Types",
    "section": "",
    "text": "If you get an error saying something like, “there is no package named lubridate” then use install.packages(\"lubridate\") and install it. You only need to do this once.↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Types</span>"
    ]
  },
  {
    "objectID": "narrative_containers.html",
    "href": "narrative_containers.html",
    "title": "4  Data Containers",
    "section": "",
    "text": "4.1 Vectors\nVectors are the most basic data container in R. They must contain data of the exact same type and are constructed using the combine() function, which is abbreviated as c() because good programmers are lazy programmers. 1\nHere is an example with some numbers.\nx &lt;- c(1,2,3)\nx\n\n[1] 1 2 3\nVectors can contain any of the base data types.\ny &lt;- c(TRUE, TRUE, FALSE, FALSE)\ny\n\n[1]  TRUE  TRUE FALSE FALSE\nz &lt;- c(\"Bob\",\"Alice\",\"Thomas\")\nz\n\n[1] \"Bob\"    \"Alice\"  \"Thomas\"\nEach vector has an inherent length representing the number of elements it contains.\nlength(x)\n\n[1] 3",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Containers</span>"
    ]
  },
  {
    "objectID": "narrative_containers.html#vectors",
    "href": "narrative_containers.html#vectors",
    "title": "4  Data Containers",
    "section": "",
    "text": "4.1.1 Introspection\nWhen asked, a vector reports the class of itself as the type of data contained within it.\n\nclass(x)\n\n[1] \"numeric\"\n\nclass(y)\n\n[1] \"logical\"\n\nclass(z)\n\n[1] \"character\"\n\n\nhowever, a vector is also a data type. As such, it has the is.vector() function. So this x can be both a vector and a numeric.\n\nis.vector( x ) && is.numeric( x )\n\n[1] TRUE\n\n\n\n\n4.1.2 Sequences\nThere are a lot of times when we require a sequnce of values and it would get a bit tedious to type them all out manually. R has several options for creating vectors that are comprised of a sequence of values.\nThe easiest type is the colon operator, that will generate a seqeunce of numerical values from the number on the left to the number on the right\n\n1:10 -&gt; y\ny\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nIt also works in the other direction (descending).\n\n10:1\n\n [1] 10  9  8  7  6  5  4  3  2  1\n\n\nHowever, it is only available to make a sequences where the increment from one value to the next is 1.\n\n3.2:5.7\n\n[1] 3.2 4.2 5.2\n\n\nFor more fine-grained control, we can use the function seq() to iterate across a range of values and specify either the step size (here from 1-10 by 3’s)\n\nseq(1,10,by=3)\n\n[1]  1  4  7 10\n\n\nOR the length of the response and it will figure out the step size to give you the right number of elements.\n\nseq( 119, 121, length.out = 6)\n\n[1] 119.0 119.4 119.8 120.2 120.6 121.0\n\n\n\n\n4.1.3 Indexing & Access\nTo access and change values within a vector, we used square brackets and the number of the entry of interest. It should be noted that in R, the first element of a vector is # 1.\nSo, to get to the third element of the x vector, we would:\n\nx[3]\n\n[1] 3\n\n\nIf you ask for values in the vector off the end (e.g., the index is beyond the length of the vector) it will return missing data.\n\nx[5]\n\n[1] NA\n\n\nIn addition to getting the values from a vector, assignment of individual values proceeds similarily.\n\nx[2] &lt;- 42\nx\n\n[1]  1 42  3\n\n\nIf you assign a value to a vector that is way off the end, it will fill in the intermediate values wtih NA for you.\n\nx[7] &lt;- 43\nx\n\n[1]  1 42  3 NA NA NA 43\n\n\n\n\n4.1.4 Vector Operations\nJust like individual values for each data type, vectors of these data types can also be operated using the same operators. Consider the two vectors x (a sequence) and y (a random selection from a Poisson distribution), both with 5 elements.\n\nx &lt;- 1:5\ny &lt;- rpois(5,2)\nx\n\n[1] 1 2 3 4 5\n\ny\n\n[1] 2 2 0 3 5\n\n\nMathematics operations are done element-wise. Here is an example using addition.\n\nx + y \n\n[1]  3  4  3  7 10\n\n\nas well as exponents.\n\nx^y\n\n[1]    1    4    1   64 3125\n\n\nIf the lengths of the vectors are not the same R will implement a recycling rule where the shorter of the vectors is repeated until you fill up the size of the longer vector. Here is an example with the 5-element x and the a new 10-element z. Notice how the values in x are repeated in the addition operaiton.\n\nz &lt;- 1:10\nx + z\n\n [1]  2  4  6  8 10  7  9 11 13 15\n\n\nIf the two vectors are not multiples of each other in length, it will still recycle the shorter one but will also give you a warning that the two vectors are not conformant (just a FYI).\n\nx + 1:8\n\nWarning in x + 1:8: longer object length is not a multiple of shorter object\nlength\n\n\n[1]  2  4  6  8 10  7  9 11\n\n\nThe operations used are dependent upon the base data type. For example, the following character values can be passed along to the paste() function to put each of the elements in the first vectoer with the corresponding values in the second vector (and specifying the separator).\n\na &lt;- c(\"Bob\",\"Alice\",\"Thomas\")\nb &lt;- c(\"Biologist\",\"Chemist\",\"Mathematician\")\npaste( a, b, sep=\" is a \")\n\n[1] \"Bob is a Biologist\"        \"Alice is a Chemist\"       \n[3] \"Thomas is a Mathematician\"\n\n\nSo, in addition to being able to work on individual values, all functions are also vector functions.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Containers</span>"
    ]
  },
  {
    "objectID": "narrative_containers.html#matrices",
    "href": "narrative_containers.html#matrices",
    "title": "4  Data Containers",
    "section": "4.2 Matrices",
    "text": "4.2 Matrices\nA matrix is a 2-dimensional container for the same kind of data as well. The two dimensions are represented as rows and columns in a rectangular configuration. Here I will make a 3x3 vector consisting of a sequence of numbers from 1 to 9.\n\nX &lt;- matrix( 1:9, nrow=3, ncol=3 )\nX\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n\nIt is a bit redundant to have both nrow and ncol with nrow * ncol = length(sequence), you can just specify one of them and it will work out the other dimension.\n\n4.2.1 Indexing\nJust like a vector, matrices use square brackets and the row & column number (in that order) to access indiviudal elements. Also, just like vectors, both rows and columns start at 1 (not zero). So to replace the value in the second row and second column with the number 42, we do this.\n\nX[2,2] &lt;- 42\nX\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2   42    8\n[3,]    3    6    9\n\n\nMatrices are actually structures fundamental to things like linear algebra. As such, there are many operations that can be applied to matrices, both unary and binary.\nA transpose is a translation of a matrix that switches the rows and columns. In R it is done by the function t(). Here I use this to define another matrix.\n\nY &lt;- t(X)\nY\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4   42    6\n[3,]    7    8    9\n\n\nBinary operators using the normal operators in the top row of your keyboard are generally element-wise operations. Here the addition of these two matrices require:\n1. Both matrices have the same number of rows.\n2. Both matrices have the same number of columns.\n3. Both matrices have the same internal data types.\nHere is an example of addition (notic how the resulting [1,1] object is equal to X[1,1] + Y[1,1])\n\nX + Y\n\n     [,1] [,2] [,3]\n[1,]    2    6   10\n[2,]    6   84   14\n[3,]   10   14   18\n\n\nThe same for element-wise multiplication.\n\nX * Y\n\n     [,1] [,2] [,3]\n[1,]    1    8   21\n[2,]    8 1764   48\n[3,]   21   48   81\n\n\nHowever, there is another kind of matrix mutliplication that sums the product or rows and columns. Since this is also a variety of multiplication but is carried out differently, we need to use a different operator. Here the matrix mutliplication operator is denoted as the combination of characters %*%.\n\nX %*% Y\n\n     [,1] [,2] [,3]\n[1,]   66  226   90\n[2,]  226 1832  330\n[3,]   90  330  126\n\n\nThis operation has a few different constraints:\n\nThe number of columns in the left matrix must equal the number of rows in the right one.\nThe resulting matrix will have the number of rows equal to that of the right matrix.\nThe resulting matrix will have the number of columns equal to that of the left matrix.\nThe resulting element at the \\(i\\) \\(j\\) position is the sum of the multipliation of the elements in the \\(i^{th}\\) row of the left matrix and the \\(j^{th}\\) column of the right one.\n\nSo the resulting element in [1,3] position is found by \\(1*3 + 4*6 + 7*9 = 90\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Containers</span>"
    ]
  },
  {
    "objectID": "narrative_containers.html#lists",
    "href": "narrative_containers.html#lists",
    "title": "4  Data Containers",
    "section": "4.3 Lists",
    "text": "4.3 Lists\nLists are a more flexible container type. Here, lists can contain different types of data in a single list. Here is an example of a list made with a few character vluaes, a numeric, a constant, and a logical value.\n\nlst &lt;- list(\"A\",\"B\",323423.3, pi, TRUE)\n\nWhen you print out a list made like this, it will indicate each element as a numeric value in double square brackets.\n\nlst\n\n[[1]]\n[1] \"A\"\n\n[[2]]\n[1] \"B\"\n\n[[3]]\n[1] 323423.3\n\n[[4]]\n[1] 3.141593\n\n[[5]]\n[1] TRUE\n\n\n\n4.3.1 Indexing\nIndexing values in a list can be done using these numbers. To get and reset the values in the second element of the list, one would:\n\nlst[[2]] &lt;- \"C\"\nlst\n\n[[1]]\n[1] \"A\"\n\n[[2]]\n[1] \"C\"\n\n[[3]]\n[1] 323423.3\n\n[[4]]\n[1] 3.141593\n\n[[5]]\n[1] TRUE\n\n\n\n\n4.3.2 Named Lists\nLists can be more valuable if we use names for the keys instead of just numbers. Here, I make an empty list and then assign values to it using names (as character values) in square brakets.\n\nmyInfo &lt;- list()\nmyInfo[\"First Name\"] &lt;- \"Rodney\"\nmyInfo[\"Second Name\"] &lt;- \"Dyer\"\nmyInfo[\"Favorite Number\"] &lt;- 42\n\nWhen showing named lists, it prints included items as:\n\nmyInfo\n\n$`First Name`\n[1] \"Rodney\"\n\n$`Second Name`\n[1] \"Dyer\"\n\n$`Favorite Number`\n[1] 42\n\n\nIn addition to the square bracket approach, we can also use as $ notation to add elements to the list (like shown above).\n\nmyInfo$Vegitarian &lt;- FALSE\n\nBoth are equivallent.\n\nmyInfo\n\n$`First Name`\n[1] \"Rodney\"\n\n$`Second Name`\n[1] \"Dyer\"\n\n$`Favorite Number`\n[1] 42\n\n$Vegitarian\n[1] FALSE\n\n\nIn addition to having different data types, you can also have different sized data types inside a list. Here I add a vector (a valid data type as shown above) to the list.\n\nmyInfo$Homes &lt;- c(\"RVA\",\"Oly\",\"SEA\")\nmyInfo\n\n$`First Name`\n[1] \"Rodney\"\n\n$`Second Name`\n[1] \"Dyer\"\n\n$`Favorite Number`\n[1] 42\n\n$Vegitarian\n[1] FALSE\n\n$Homes\n[1] \"RVA\" \"Oly\" \"SEA\"\n\n\nTo access these values, we can use a combination of $ notation and [] on the resulting vector.\n\nmyInfo$Homes[2]\n\n[1] \"Oly\"\n\n\nWhen elements in a list are defined using named keys, the list itself can be asked for the keys using names().\n\nnames(myInfo)\n\n[1] \"First Name\"      \"Second Name\"     \"Favorite Number\" \"Vegitarian\"     \n[5] \"Homes\"          \n\n\nThis can be helpful at times when you did not create the list yourself and want to see what is inside of them.\n\n\n4.3.3 Spaces in Names\nAs you see above, this list has keys such as “First Name” and “Vegitarian”. The first one has a space inside of it whereas the second one does not. This is a challenge. If we were to try to use the first key as\n\nmyInfo$First Name\n\nWould give you an error (if I ran the chunck but I cannot because it is an error and won’t let me compile this document if I do). For names that have spaces, we need to enclose them inside back-ticks (as shown in the output above).\n\nmyInfo$`First Name`\n\n[1] \"Rodney\"\n\n\nSo feel free to use names that make sense, but if you do, you’ll need to treat them a bit specially using the backticks.\n\n\n4.3.4 Analysis Output\nBy far, the most common location for lists is when you do some kind of analysis. Almost all analyses return the restuls as a special kind of list.\nHere is an example looking at some data from three species of Iris on the lengths and width of sepal and petals. The data look like:\n\n\n\n\n\n\n\n\nFigure 4.1: The distribution of sepal and petal lengths from three species of Iris.\n\n\n\n\n\nWe can look at the correlation between two variable using the built-in cor.test() function.\n\niris.test &lt;- cor.test( iris$Sepal.Length, iris$Petal.Length )\n\nWe can print the output and it will format the results in a proper way.\n\niris.test\n\n\n    Pearson's product-moment correlation\n\ndata:  iris$Sepal.Length and iris$Petal.Length\nt = 21.646, df = 148, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8270363 0.9055080\nsample estimates:\n      cor \n0.8717538 \n\n\nHowever, the elements in the iris.test are simply a list.\n\nnames(iris.test)\n\n[1] \"statistic\"   \"parameter\"   \"p.value\"     \"estimate\"    \"null.value\" \n[6] \"alternative\" \"method\"      \"data.name\"   \"conf.int\"   \n\n\nIf fact, the contents of the output are just keys and values, even though when we printed it all out, it was formatted as a much more informative output.\n\n\n\n\n\n\n\n\n\nValues\n\n\n\n\nstatistic.t\n21.6460193457598\n\n\nparameter.df\n148\n\n\np.value\n1.03866741944975e-47\n\n\nestimate.cor\n0.871753775886583\n\n\nnull.value.correlation\n0\n\n\nalternative\ntwo.sided\n\n\nmethod\nPearson's product-moment correlation\n\n\ndata.name\niris$Sepal.Length and iris$Petal.Length\n\n\nconf.int1\n0.827036329664362\n\n\nconf.int2\n0.905508048821454\n\n\n\n\n\n\n\nWe will come back to this special kind of printing later when discussing functions but for now, lets just consider how cool this is because we can access the raw values of the analysis directly. We an also easily incorporate the findings of analyses, such as this simple correlation test, and insert the content into the text. All you have to do is address the components of the analysis as in-text r citation. Here is an example where I include the values of:\n\niris.test$estimate\n\n      cor \n0.8717538 \n\niris.test$statistic\n\n       t \n21.64602 \n\niris.test$p.value\n\n[1] 1.038667e-47\n\n\nHere is an example paragraph (see the raw quarto document to see the formatting).\n\nThere was a significant relationship between sepal and petal length (Pearson Correlation, \\(\\rho =\\) 0.872, \\(t =\\) 21.6, P = 1.04e-47).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Containers</span>"
    ]
  },
  {
    "objectID": "narrative_containers.html#data-frames",
    "href": "narrative_containers.html#data-frames",
    "title": "4  Data Containers",
    "section": "4.4 Data Frames",
    "text": "4.4 Data Frames\nThe data.frame is the most common container for all the data you’ll be working with in R. It is kind of like a spreadsheet in that each column of data is the same kind of data measured on all objects (e.g., weight, survival, population, etc.) and each row represents one observation that has a bunch of different kinds of measurements associated with it.\nHere is an example with three different data types (the z is a random sample of TRUE/FALSE equal in length to the other elements).\n\nx &lt;- 1:10\ny &lt;- LETTERS[11:20]\nz &lt;- sample( c(TRUE,FALSE), size=10, replace=TRUE )\n\nI can put them into a data.frame object as:\n\ndf &lt;- data.frame( TheNums = x,\n                  TheLetters = y,\n                  TF = z\n                  )\ndf\n\n   TheNums TheLetters    TF\n1        1          K FALSE\n2        2          L  TRUE\n3        3          M FALSE\n4        4          N  TRUE\n5        5          O  TRUE\n6        6          P FALSE\n7        7          Q FALSE\n8        8          R FALSE\n9        9          S  TRUE\n10      10          T FALSE\n\n\nSince each column is its own ‘type’ we can easily get a summary of the elements within it using summary().\n\nsummary( df )\n\n    TheNums       TheLetters            TF         \n Min.   : 1.00   Length:10          Mode :logical  \n 1st Qu.: 3.25   Class :character   FALSE:6        \n Median : 5.50   Mode  :character   TRUE :4        \n Mean   : 5.50                                     \n 3rd Qu.: 7.75                                     \n Max.   :10.00                                     \n\n\nAnd depending upon the data type, the output may give numerical, counts, or just description of the contents.\n\n4.4.1 Indexing\nJust like a list, a data.frame can be defined as having named columns. The distinction here is that each column should have the same number of elements in it, whereas a list may have differnet lengths to the elements.\n\nnames( df )\n\n[1] \"TheNums\"    \"TheLetters\" \"TF\"        \n\n\nAnd like the list, we can easily use the $ operator to access the vectors components.\n\ndf$TheLetters\n\n [1] \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\" \"T\"\n\nclass( df$TheLetters )\n\n[1] \"character\"\n\n\nIndexing and grabbing elements can be done by either the column name (with $) and a square bracket OR by the [row,col] indexing like the matrix above.\n\ndf$TheLetters[3]\n\n[1] \"M\"\n\ndf[3,2]\n\n[1] \"M\"\n\n\nJust like a matrix, the dimensions of the data.frame is defined by the number of rows and columns.\n\ndim( df )\n\n[1] 10  3\n\nnrow( df )\n\n[1] 10\n\nncol( df )\n\n[1] 3\n\n\n\n\n4.4.2 Loading Data\nBy far, you will most often NOT be making data by hand but instead will be loading it from external locations. here is an example of how we can load in a CSV file that is located in the GitHub repository for this topic. As this is a public repository, we can get a direct URL to the file. For simplicity, I’ll load in tidyverse and use some helper functions contained therein.\n\nlibrary( tidyverse )\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.1     ✔ stringr   1.6.0\n✔ lubridate 1.9.4     ✔ tibble    3.3.0\n✔ purrr     1.2.0     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nThe URL for this repository is\n\nurl &lt;- \"https://raw.githubusercontent.com/DyerlabTeaching/Data-Containers/main/data/arapat.csv\"\n\nAnd we can read it in directly (as long as we have an internet connection) as:\n\nbeetles &lt;- read_csv( url )\n\nRows: 39 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Stratum\ndbl (2): Longitude, Latitude\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNotice how the funtion tells us a few things about the data.\nThe data itself consists of:\n\nsummary( beetles )\n\n   Stratum            Longitude         Latitude    \n Length:39          Min.   :-114.3   Min.   :23.08  \n Class :character   1st Qu.:-112.9   1st Qu.:24.52  \n Mode  :character   Median :-111.5   Median :26.21  \n                    Mean   :-111.7   Mean   :26.14  \n                    3rd Qu.:-110.4   3rd Qu.:27.47  \n                    Max.   :-109.1   Max.   :29.33  \n\n\nwhich looks like:\n\nbeetles\n\n# A tibble: 39 × 3\n   Stratum Longitude Latitude\n   &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;\n 1 88          -114.     29.3\n 2 9           -114.     29.0\n 3 84          -114.     29.0\n 4 175         -113.     28.7\n 5 177         -114.     28.7\n 6 173         -113.     28.4\n 7 171         -113.     28.2\n 8 89          -113.     28.0\n 9 159         -113.     27.5\n10 SFr         -113.     27.4\n# ℹ 29 more rows\n\n\nWe can quickly use these data and make an interactive labeled map of it in a few lines of code (click on a marker).\n\nlibrary( leaflet )\nbeetles %&gt;%\n  leaflet() %&gt;%\n  addProviderTiles(provider = providers$Esri.WorldTopo) %&gt;%\n  addMarkers( ~Longitude, ~Latitude,popup = ~Stratum )",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Containers</span>"
    ]
  },
  {
    "objectID": "narrative_containers.html#questions",
    "href": "narrative_containers.html#questions",
    "title": "4  Data Containers",
    "section": "4.5 Questions",
    "text": "4.5 Questions\nIf you have any questions for me specifically on this topic, please post as an Issue in your repository, otherwise consider posting to the discussion board on Canvas.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Containers</span>"
    ]
  },
  {
    "objectID": "narrative_containers.html#footnotes",
    "href": "narrative_containers.html#footnotes",
    "title": "4  Data Containers",
    "section": "",
    "text": "The more lines of code that you write, the more likely there will be either a grammatical error (easier to find) or a logical one (harder to find).↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Containers</span>"
    ]
  },
  {
    "objectID": "narrative_tidyverse.html",
    "href": "narrative_tidyverse.html",
    "title": "5  Tidyverse",
    "section": "",
    "text": "5.1 The Tidyverse Approach\nThis is the first introduction to tidyverse and is the key skill necessary to become proficient at data analysis.\nlibrary( tidyverse )\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.1     ✔ stringr   1.6.0\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.2.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary( lubridate )",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "narrative_tidyverse.html#the-tidyverse-approach",
    "href": "narrative_tidyverse.html#the-tidyverse-approach",
    "title": "5  Tidyverse",
    "section": "",
    "text": "5.1.1 The Data\nFor this topic we will use some example data from the Rice Rivers Center. These data represent both atmospheric and water data collected from instrumentation on-site. I have stored these data in a spreadsheet that is shared on Google Drive as a CSV file.\nYou can look at it here.\n\n\n5.1.2 The Data in R\nSo let’s load it into memory and take a look at it.\n\nurl &lt;- \"https://docs.google.com/spreadsheets/d/1Mk1YGH9LqjF7drJE-td1G_JkdADOU0eMlrP01WFBT8s/pub?gid=0&single=true&output=csv\"\nrice &lt;- read_csv( url )\n\nRows: 8199 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): DateTime\ndbl (22): RecordID, PAR, WindSpeed_mph, WindDir, AirTempF, RelHumidity, BP_H...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsummary( rice )\n\n   DateTime            RecordID          PAR           WindSpeed_mph   \n Length:8199        Min.   :43816   Min.   :   0.000   Min.   : 0.000  \n Class :character   1st Qu.:45866   1st Qu.:   0.000   1st Qu.: 2.467  \n Mode  :character   Median :47915   Median :   0.046   Median : 4.090  \n                    Mean   :47915   Mean   : 241.984   Mean   : 5.446  \n                    3rd Qu.:49964   3rd Qu.: 337.900   3rd Qu.: 7.292  \n                    Max.   :52014   Max.   :1957.000   Max.   :30.650  \n                                                                       \n    WindDir          AirTempF       RelHumidity        BP_HG      \n Min.   :  0.00   Min.   : 3.749   Min.   :15.37   Min.   :29.11  \n 1st Qu.: 37.31   1st Qu.:31.545   1st Qu.:42.25   1st Qu.:29.87  \n Median :137.30   Median :37.440   Median :56.40   Median :30.01  \n Mean   :146.20   Mean   :38.795   Mean   :58.37   Mean   :30.02  \n 3rd Qu.:249.95   3rd Qu.:46.410   3rd Qu.:76.59   3rd Qu.:30.21  \n Max.   :360.00   Max.   :74.870   Max.   :93.00   Max.   :30.58  \n                                                                  \n    Rain_in            H2O_TempC       SpCond_mScm      Salinity_ppt   \n Min.   :0.0000000   Min.   :-0.140   Min.   :0.0110   Min.   :0.0000  \n 1st Qu.:0.0000000   1st Qu.: 3.930   1st Qu.:0.1430   1st Qu.:0.0700  \n Median :0.0000000   Median : 5.450   Median :0.1650   Median :0.0800  \n Mean   :0.0008412   Mean   : 5.529   Mean   :0.1611   Mean   :0.0759  \n 3rd Qu.:0.0000000   3rd Qu.: 7.410   3rd Qu.:0.1760   3rd Qu.:0.0800  \n Max.   :0.3470000   Max.   :13.300   Max.   :0.2110   Max.   :0.1000  \n                     NA's   :1        NA's   :1        NA's   :1       \n       PH           PH_mv        Turbidity_ntu       Chla_ugl    \n Min.   :6.43   Min.   :-113.8   Min.   :  6.20   Min.   :  1.3  \n 1st Qu.:7.50   1st Qu.: -47.8   1st Qu.: 15.50   1st Qu.:  3.7  \n Median :7.58   Median : -43.8   Median : 21.80   Median :  6.7  \n Mean   :7.60   Mean   : -44.5   Mean   : 24.54   Mean   :137.3  \n 3rd Qu.:7.69   3rd Qu.: -38.9   3rd Qu.: 30.30   3rd Qu.:302.6  \n Max.   :9.00   Max.   :  28.5   Max.   :187.70   Max.   :330.1  \n NA's   :1      NA's   :1        NA's   :1        NA's   :1      \n   BGAPC_CML        BGAPC_rfu         ODO_sat         ODO_mgl     \n Min.   :   188   Min.   :  0.10   Min.   : 87.5   Min.   :10.34  \n 1st Qu.:   971   1st Qu.:  0.50   1st Qu.: 99.2   1st Qu.:12.34  \n Median :  1369   Median :  0.70   Median :101.8   Median :12.88  \n Mean   :153571   Mean   : 72.91   Mean   :102.0   Mean   :12.88  \n 3rd Qu.:345211   3rd Qu.:163.60   3rd Qu.:104.1   3rd Qu.:13.34  \n Max.   :345471   Max.   :163.70   Max.   :120.8   Max.   :14.99  \n NA's   :1        NA's   :1        NA's   :1       NA's   :1      \n    Depth_ft        Depth_m      SurfaceWaterElev_m_levelNad83m\n Min.   :12.15   Min.   :3.705   Min.   :-32.53                \n 1st Qu.:14.60   1st Qu.:4.451   1st Qu.:-31.78                \n Median :15.37   Median :4.684   Median :-31.55                \n Mean   :15.34   Mean   :4.677   Mean   :-31.55                \n 3rd Qu.:16.12   3rd Qu.:4.913   3rd Qu.:-31.32                \n Max.   :17.89   Max.   :5.454   Max.   :-30.78                \n                                                               \n\n\nThese data represent measurements taken every 15 minutes, 24 hours a day, 7 days a week, 365 days a year. For brevity, this file contains measurements starting at 1/1/2014 12:00:00 AM and ending at 3/27/2014 9:30:00 AM (only 8199 records here…).\nIf you look at the summary of the data above, you will see several things, including:\n\nDate and time objects are character\nSome measurements are in Standard and some in Imperial with units in the same file include both °F and °C, as well as measurements in meters, feet, and inches. In fact, there are duplication of data columns in different units (guess what kind of correlation they might have…)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "narrative_tidyverse.html#verbs-of-analysis",
    "href": "narrative_tidyverse.html#verbs-of-analysis",
    "title": "5  Tidyverse",
    "section": "5.2 Verbs of Analysis",
    "text": "5.2 Verbs of Analysis\nWhen we perform any type of data manipulation, we use specific verbs. There is a limited lexicon for us to use, but the key here is how we perform these actions, and in which order they are deployed for a huge diversity in outcomes. For now, these basic verbs include:\n\nSelect: Used to grab or reorder columns of data.\nFilter: Used to grab subsets of records (rows) based upon some criteria.\nMutate: Create new columns of data based upon manipulations of existing columns.\nArrange: Order the records (rows) based upon some criteria.\nGroup: Gather records together to perform operations on chunks of them similar to by().\nSummarize: Extract summaries of data (or grouped data) based upon some defined criteria.\n\nIn the following examples, we’ll be using the rice data above. For each verb, I’m going to use the pipe operator (%&gt;%) to send the data into the example functions and then assign the result to a dummy data.frame named df. The arguments passed to each of the verbs are where the magic happens.\n\n5.2.1 The Output\nThe key to these activities is that every one of these functions takes a data.frame as input, does its operations on it, then return a data.frame object as output. The data.frame is the core data container for all of these actions.\n\n\n5.2.2 Select Operator\nThe select() function allows you to choose which columns of data to work with.\n\nrice %&gt;%\n  select( DateTime, AirTempF ) -&gt; df \nhead(df)\n\n# A tibble: 6 × 2\n  DateTime             AirTempF\n  &lt;chr&gt;                   &lt;dbl&gt;\n1 1/1/2014 12:00:00 AM     31.0\n2 1/1/2014 12:15:00 AM     30.7\n3 1/1/2014 12:30:00 AM     31.2\n4 1/1/2014 12:45:00 AM     30.5\n5 1/1/2014 1:00:00 AM      30.9\n6 1/1/2014 1:15:00 AM      30.6\n\n\nSelect can also be used to reorder the columns in a data.frame object. Here are the names of the data columns as initially loaded.\n\nnames( rice )\n\n [1] \"DateTime\"                       \"RecordID\"                      \n [3] \"PAR\"                            \"WindSpeed_mph\"                 \n [5] \"WindDir\"                        \"AirTempF\"                      \n [7] \"RelHumidity\"                    \"BP_HG\"                         \n [9] \"Rain_in\"                        \"H2O_TempC\"                     \n[11] \"SpCond_mScm\"                    \"Salinity_ppt\"                  \n[13] \"PH\"                             \"PH_mv\"                         \n[15] \"Turbidity_ntu\"                  \"Chla_ugl\"                      \n[17] \"BGAPC_CML\"                      \"BGAPC_rfu\"                     \n[19] \"ODO_sat\"                        \"ODO_mgl\"                       \n[21] \"Depth_ft\"                       \"Depth_m\"                       \n[23] \"SurfaceWaterElev_m_levelNad83m\"\n\n\nLet’s say that you wanted to reorder the columns as RecordID, ODO_mgl and PH as the first three columns and leave everything else as is. There is this cool function everthying() that helps out.\n\nrice %&gt;%\n  select( RecordID, ODO_mgl, PH, everything() ) -&gt; df\nnames( df )\n\n [1] \"RecordID\"                       \"ODO_mgl\"                       \n [3] \"PH\"                             \"DateTime\"                      \n [5] \"PAR\"                            \"WindSpeed_mph\"                 \n [7] \"WindDir\"                        \"AirTempF\"                      \n [9] \"RelHumidity\"                    \"BP_HG\"                         \n[11] \"Rain_in\"                        \"H2O_TempC\"                     \n[13] \"SpCond_mScm\"                    \"Salinity_ppt\"                  \n[15] \"PH_mv\"                          \"Turbidity_ntu\"                 \n[17] \"Chla_ugl\"                       \"BGAPC_CML\"                     \n[19] \"BGAPC_rfu\"                      \"ODO_sat\"                       \n[21] \"Depth_ft\"                       \"Depth_m\"                       \n[23] \"SurfaceWaterElev_m_levelNad83m\"\n\n\n\n\n5.2.3 Filter\nThe function filter() works to select records (rows) based upon some criteria. So for example, if I am interested in just records when the airtemp was freezing (and the raw data are in °F). The range of values in the original data was:\n\nrange( rice$AirTempF )\n\n[1]  3.749 74.870\n\n\nbut after filtering using the name of the variable and a logical operator.\n\nrice %&gt;%\n  filter( AirTempF &lt; 32 ) -&gt; df\nrange( df$AirTempF )\n\n[1]  3.749 31.990\n\n\nJust like select(), it is possible to have several conditions, that are compounded (using a logical AND operator) by adding them to the filter() function. Here I also split the conditionals requiring the data to be above freezing air temperatures, not missing data from the PH meter, and water turbidity &lt; 15 ntu’s. I also put each of these onto their own lines and auto-indent does a great job of making it reasonably readable.\n\nrice %&gt;%\n  filter( AirTempF &gt; 32, \n          !is.na(PH), \n          Turbidity_ntu &lt; 15) -&gt; df\nnrow(df)\n\n[1] 1449\n\n\n\n\n5.2.4 Mutate\nThe mutate() function changes values in the table and is quite versatile. Here I will jump back to our old friend mdy_hms() from lubridate and convert the DateTime column, which is\n\nclass( rice$DateTime )\n\n[1] \"character\"\n\n\nand convert it into a real date and time object\n\nrice %&gt;%\n  mutate( Date = mdy_hms(DateTime, tz = \"EST\") ) -&gt; df\nclass( df$Date )\n\n[1] \"POSIXct\" \"POSIXt\" \n\nsummary( df$Date )\n\n                 Min.               1st Qu.                Median \n\"2014-01-01 00:00:00\" \"2014-01-22 08:22:30\" \"2014-02-12 16:45:00\" \n                 Mean               3rd Qu.                  Max. \n\"2014-02-12 16:45:00\" \"2014-03-06 01:07:30\" \"2014-03-27 09:30:00\" \n\n\nYou can also create several mutations in one mutation step.\n\nrice %&gt;%\n  mutate( Date = mdy_hms(DateTime, tz = \"EST\"), \n          Month = month(Date, label = TRUE) ) -&gt; df\nsummary( df$Month )\n\n Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec \n2976 2688 2535    0    0    0    0    0    0    0    0    0 \n\n\n\n\n5.2.5 Arrange\nWe can sort entire data.frame objects based upon the values in one or more of the columns using the arrange() function.\n\nrice %&gt;%\n  arrange( WindSpeed_mph ) -&gt; df \ndf$WindSpeed_mph[1]\n\n[1] 0\n\n\nBy default, it is in ascending order, to reverse it, use the negative operator on the column name object in the function.\n\nrice %&gt;%\n  arrange( -WindSpeed_mph ) -&gt; df \ndf$WindSpeed_mph[1]\n\n[1] 30.65\n\n\nAs above, it is possible to combine many columns of data as criteria for sorting by adding more arguments to the function call.\n\nrice %&gt;%\n  arrange( -WindSpeed_mph, WindDir ) -&gt; df\n\n\n\n5.2.6 Summarise\nThis function is the first one that does not return some version of the original data that was passed to it. Rather, this performs operations on the data and makes a brand new data.frame object.\nEach argument you give to the function performs one or more operations on the data and returns a brand new data.frame object with only the the values specified.\nHere is an example where I am taking the mean air and water temperature (n.b., one is in °F and the other is in °C). Notice the result is a new data.frame object with one row and two new columns defined by how I asked for the summary in the first place. I used single tick notation so I can have a space in the column names.\n\nrice %&gt;%\n  summarize( `Air Temp` = mean( AirTempF), \n             `Water Temp` = mean(H2O_TempC, na.rm=TRUE))\n\n# A tibble: 1 × 2\n  `Air Temp` `Water Temp`\n       &lt;dbl&gt;        &lt;dbl&gt;\n1       38.8         5.53\n\n\n\n\n5.2.7 Group & Summarize\nTo get more than one row in the resulting data.frame from summary(), we need to group the data in some way. The function group_by() does this and is used prior to summary(). Let’s take a look at how we can get the average air and water temp by month. To do this, I’m going to have to do several steps. I’m just going to chain them together using the %&gt;% operator.\n\nrice %&gt;%\n  mutate( Date = mdy_hms( DateTime, \n                          tz=\"EST\"),\n          Month = month( Date, \n                         abbr = FALSE, \n                         label=TRUE) ) %&gt;%\n  group_by( Month ) %&gt;%\n  summarize( `Air Temp` = mean( AirTempF), \n             `Water Temp` = mean( H2O_TempC, \n                                  na.rm=TRUE) )\n\n# A tibble: 3 × 3\n  Month    `Air Temp` `Water Temp`\n  &lt;ord&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1 January        34.7         3.68\n2 February       39.7         5.29\n3 March          42.6         7.96\n\n\nAs you read the code, notice how easy it is to understand what is going on because of both the pipes and because of the way I am formatting the code itself.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "narrative_tidyverse.html#flows",
    "href": "narrative_tidyverse.html#flows",
    "title": "5  Tidyverse",
    "section": "5.3 Flows",
    "text": "5.3 Flows\nThis last part really showed off the process of multi-step data manipulations using the pipe operator and the several verbs we introduced. These are both efficient in terms of typing as well as efficient in the way of producing research that makes sense to look at.\nHere are some strategies that I use when building up these manipulation workflows.\n\nDo not think that you have to do the whole thing at once. I typically build up the workflow, one line at a time. Make sure the output from the previous line is what you think it should be then add the next one.\nKeep your code open and airy, it makes it easier to read and to catch any logical errors that may arrise.\nYou can pipe into a lot of different functions. In fact, any function that takes a data frame can be the recipient of a pipe. While developing a workflow, I will often pipe into things like head(), summary(), or View() to take a look at what is coming out of my workflow to make sure it resembles what I think it should look like.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "narrative_tidyverse.html#questions",
    "href": "narrative_tidyverse.html#questions",
    "title": "5  Tidyverse",
    "section": "5.4 Questions",
    "text": "5.4 Questions\nIf you have any questions for me specifically on this topic, please post as an Issue in your repository, otherwise consider posting to the discussion board on Canvas.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "narrative_classic.html",
    "href": "narrative_classic.html",
    "title": "6  Data Visualization",
    "section": "",
    "text": "6.1 The Data\nThe iris flower data set (also known as Fisher’s Iris data set) is a multivariate data set introduced by the British statistician, eugenicist, and biologist Ronald Fisher in his 1936 paper entitled, The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis.\nThese data are part of the base R distribution and contain sepal and pedal measurements for three species if congeneric plants, Iris setosa, I. versicolor, and I. virginica.\nHere is what the data summary looks like.\nsummary(iris)\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "narrative_classic.html#the-data",
    "href": "narrative_classic.html#the-data",
    "title": "6  Data Visualization",
    "section": "",
    "text": "The three species of iris in the default data set.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "narrative_classic.html#basic-plotting-in-r",
    "href": "narrative_classic.html#basic-plotting-in-r",
    "title": "6  Data Visualization",
    "section": "6.2 Basic Plotting in R",
    "text": "6.2 Basic Plotting in R\nThe base R comes with several built-in plotting functions, each of which is accessed through a single function with a wide array of optional arguments that modify the overall appearance.\nHistograms - The Density of A Single Data Vector\n\nhist( iris$Sepal.Length)\n\n\n\n\n\n\n\n\nYou can see that the default values for the hist() function label the x-axis & title on the graph have the names of the variable passed to it, with a y-axis is set to “Frequency”.\n\nxlab & ylab: The names attached to both x- and y-axes.\nmain: The title on top of the graph.\nbreaks: This controls the way in which the original data are partitioned (e.g., the width of the bars along the x-axis).\n\nIf you pass a single number, n to this option, the data will be partitioned into n bins.\nIf you pass a sequence of values to this, it will use this sequence as the boundaries of bins.\n\ncol: The color of the bar (not the border)\nprobability: A flag as either TRUE or FALSE (the default) to have the y-axis scaled by total likelihood of each bins rather than a count of the numbrer of elements in that range.\n\nDensity - Estimating the continuous density of data\n\nd_sepal.length &lt;- density( iris$Sepal.Length )\nd_sepal.length\n\n\nCall:\n    density.default(x = iris$Sepal.Length)\n\nData: iris$Sepal.Length (150 obs.); Bandwidth 'bw' = 0.2736\n\n       x               y           \n Min.   :3.479   Min.   :0.000148  \n 1st Qu.:4.790   1st Qu.:0.034088  \n Median :6.100   Median :0.153218  \n Mean   :6.100   Mean   :0.190407  \n 3rd Qu.:7.410   3rd Qu.:0.378921  \n Max.   :8.721   Max.   :0.396476  \n\n\nThe density() function estimates a continuous probability density function for the data and returns an object that has both x and y values. In fact, it is a special kind of object.\n\nclass(d_sepal.length)\n\n[1] \"density\"\n\n\nBecause of this, the general plot() function knows how to plot these kinds of things.\n\nplot( d_sepal.length )\n\n\n\n\n\n\n\n\nNow, the general plot() function has A TON of options and is overloaded to be able to plot all kinds of data. In addition to xlab and ylab, we modify the following:\n\ncol: Color of the line.\nlwd: Line width\nbty: This covers the ‘box type’, which is the square box around the plot area. I typically use bty=\"n\" because I hate those square boxes around my plots (compare the following 2 plots to see the differences). But you do you.\nxlim & ylim: These dictate the range on both the x- and y-axes. It takes a pair of values such as c(min,max) and then limits (or extends) that axis to to fill that range.\n\nScatter Plots - Plotting two variables\n\nplot( iris$Sepal.Length, iris$Sepal.Width  )\n\n\n\n\n\n\n\n\nHere is the most general plot(). The form of the arguments to this function are x-data and then y-data. The visual representation of the data is determined by the optional values you pass (or if you do not pass any optional values, the default is the scatter plot shown above)\n\n\n\n\n\n\n\nParameter\nDescription\n\n\n\n\ntype\nThe kind of plot to show (’p’oint, ’l’ine, ’b’oth, or ’o’ver). A point plot is the default.\n\n\npch\nThe character (or symbol) being used to plot. There 26 recognized general characters to use for plotting. The default is pch=1.\n\n\ncol\nThe color of the symbols/lines that are plot.\n\n\ncex\nThe magnification size of the character being plot. The default is cex=1 and deviation from that will increase (\\(cex &gt; 1\\)) or decrease (\\(0 &lt; cex &lt; 1\\)) the scaling of the symbols.\n\n\nlwd\nThe width of any lines in the plot.\n\n\nlty\nThe type of line to be plot (solid, dashed, etc.)\n\n\n\n\n\n\n\n\n\n\n\n\nOne of the relevant things you can use the parameter pch for is to differentiate between groups of observations (such as different species for example). Instead of giving it one value, pass it a vector of values whose length is equal to that for x- and y-axis data.\nHere is an example where I coerce the iris$Species data vector into numeric types and use that for symbols.\n\nsymbol &lt;- as.numeric(iris$Species)\nsymbol\n\n  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n [75] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3\n[112] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n[149] 3 3\n\n\n\nplot( iris$Sepal.Length, iris$Sepal.Width, pch=symbol )\n\n\n\n\n\n\n\n\nWe can use the same technique to use col instead of pch. Here I make a vector of color names and then use the previously defined in the variable symbol.\n\nraw_colors &lt;- c(\"red\",\"gold\",\"forestgreen\")\ncolors &lt;- raw_colors[ symbol ]\ncolors[1:10]\n\n [1] \"red\" \"red\" \"red\" \"red\" \"red\" \"red\" \"red\" \"red\" \"red\" \"red\"\n\n\nIn addition to the general form for the function plot(x,y) we used above, we can use an alternative designation based upon what is called the functional form. The functional form is how we designate functions in R, such as regression anlaysis. This basic syntax for this is y ~ x, that is the response variable (on the y-axis) is a function of the predictor (on the x-axis).\nFor simplicty, I’ll make x and y varibles pointing to the same same data as in the previous graph.\n\ny &lt;- iris$Sepal.Width\nx &lt;- iris$Sepal.Length\n\nThen, the plot() function can be written as (including all the fancy additional stuff we just described):\n\nplot( y ~ x , \n      col=colors, \n      pch=20, \n      bty=\"n\", \n      xlab=\"Sepal Length\", ylab=\"Sepal Width\")\n\n\n\n\n\n\n\n\nThis is much easier to read (also notice how I used serveral lines to put in all the options to the plot function for legibility).\nBar Plots - Quantifying Counts\nThe barplot function takes a set of heights, one for each bar. Let’s quickly grab the mean length for sepals across all three species. There are many ways to do this, here are two, the first being more pedantic and the second more concise.\nThe iris data is in a data.frame that has a column designating the species. We can see which ones using unique().\n\nunique( iris$Species )\n\n[1] setosa     versicolor virginica \nLevels: setosa versicolor virginica\n\n\nTo estimate the mean for each species, we can take values in iris$Sepal.Length for each level of iris$Species using indices.\n\nmu.Setosa &lt;- mean( iris$Sepal.Length[ iris$Species == \"setosa\" ])\nmu.Versicolor &lt;- mean( iris$Sepal.Length[ iris$Species == \"versicolor\" ])\nmu.Virginica &lt;- mean( iris$Sepal.Length[ iris$Species == \"virginica\" ])\n\nmeanSepalLength &lt;- c( mu.Setosa, mu.Versicolor, mu.Virginica )\nmeanSepalLength\n\n[1] 5.006 5.936 6.588\n\n\nWhen we plot these data using barplot() we pass the values and set the names of the bars us\n\nbarplot( meanSepalLength, \n         names.arg = c(\"setosa\",\"versicolor\",\"virginica\"), \n         xlab=\"Iris Species\",\n         ylab=\"Mean Sepal Length\")\n\n\n\n\n\n\n\n\nThe second way to do this is to use the by() function (see ?by for the complete help file). The by function takes the following objects:\n\nThe raw data to use as measurements. Here we will use iris$Sepal.Length as the raw data.\nData designating groups to partition the raw data into (we will use iris$Species).\nThe function that you want to use on each group. (here we will ask for the mean).\n\n\nmeanSepalLength &lt;- by( iris$Sepal.Length, iris$Species, mean )\nmeanSepalLength\n\niris$Species: setosa\n[1] 5.006\n------------------------------------------------------------ \niris$Species: versicolor\n[1] 5.936\n------------------------------------------------------------ \niris$Species: virginica\n[1] 6.588\n\n\nThe data returned from this function is both numeric and has a name set for each value.\n\nis.numeric( meanSepalLength )\n\n[1] TRUE\n\nnames( meanSepalLength )\n\n[1] \"setosa\"     \"versicolor\" \"virginica\" \n\n\nThen when we pass that to barplot() the column labels are set automatically (e.g., no need to set names.arg as above).\n\nbarplot( meanSepalLength, \n         xlab = \"Iris Species\",\n         ylab = \"Average Sepal Length\")\n\n\n\n\n\n\n\n\nBoxplots - High density information\nA boxplot contains a high amount of information content and is appropriate when the groupings on the x-axis are categorical. For each category, the graphical representation includes:\n\nThe median value for the raw data\nA box indicating the area between the first and third quartile (e.g,. the values enclosing the 25% - 75% of the data). The top and bottoms are often referred to as the hinges of the box.\nA notch (if requested), represents confidence around the estimate of the median.\nWhiskers extending out to shows \\(\\pm 1.5 * IQR\\) (the Inner Quartile Range)\nAny points of the data that extend beyond the whiskers are plot as points.\n\nFor legibility, we can use the functional form for the plots as well as separate out the data.frame from the columns using the optional data= argument.\n\nboxplot( Sepal.Length ~ Species, \n         data = iris, \n         notch=TRUE, \n         ylab=\"Sepal Length\" )",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "narrative_classic.html#colors",
    "href": "narrative_classic.html#colors",
    "title": "6  Data Visualization",
    "section": "6.3 Colors",
    "text": "6.3 Colors\nNamed Colors -  There are 657 pre-defined, named colors built into the base R distribution. Here is a random selection of those values.\n\nrandomColors &lt;- sample( colors(), size = nrow(iris) )\nhead(randomColors)\n\n[1] \"royalblue1\" \"grey17\"     \"gray41\"     \"palegreen2\" \"purple2\"   \n[6] \"lightcyan\" \n\n\nTo use these colors, you can specify them by name for either all the elements\n\nboxplot( Sepal.Length ~ Species, \n         data = iris, \n         col = randomColors[1],\n         notch=TRUE, \n         ylab=\"Sepal Length\" )\n\n\n\n\n\n\n\n\nor for each element individually.\n\nboxplot( Sepal.Length ~ Species, \n         data = iris, \n         col = randomColors[1:3],\n         notch=TRUE, \n         ylab=\"Sepal Length\" )\n\n\n\n\n\n\n\n\nHex Colors:  You can also use hexadecimal representations of colors, which is most commonly used on the internet. A hex representation of colors consists of red, green, and blue values encoded as numbers in base 16 (e.g., the single digits 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, F). There are a lot of great resources on the internet for color themes that report red, green, blue and hex values. I often use the coolors.co website to look for themes that go well together for slides or presentations.\nColor Brewer Finally, there is an interesting website at colorbrewer2.org that has some interesting built-in palettes. There is an associated library that makes creating palettes for plots really easy and as you get more expreienced with R, you will find this very helpful. For quick visualizations and estimation of built-in color palettes, you can look at the website (below).\n or look at the colors in R\n\nlibrary(RColorBrewer)\ndisplay.brewer.all()\n\n\n\n\n\n\n\n\nThere are three basic kinds of palettes: divergent, qualitative, and sequential. Each of these built-in palletes has a maximum number of colors available (though as you see below we can use them to interpolate larger sets) as well as indications if the palette is safe for colorblind individuals.\n\nbrewer.pal.info\n\n         maxcolors category colorblind\nBrBG            11      div       TRUE\nPiYG            11      div       TRUE\nPRGn            11      div       TRUE\nPuOr            11      div       TRUE\nRdBu            11      div       TRUE\nRdGy            11      div      FALSE\nRdYlBu          11      div       TRUE\nRdYlGn          11      div      FALSE\nSpectral        11      div      FALSE\nAccent           8     qual      FALSE\nDark2            8     qual       TRUE\nPaired          12     qual       TRUE\nPastel1          9     qual      FALSE\nPastel2          8     qual      FALSE\nSet1             9     qual      FALSE\nSet2             8     qual       TRUE\nSet3            12     qual      FALSE\nBlues            9      seq       TRUE\nBuGn             9      seq       TRUE\nBuPu             9      seq       TRUE\nGnBu             9      seq       TRUE\nGreens           9      seq       TRUE\nGreys            9      seq       TRUE\nOranges          9      seq       TRUE\nOrRd             9      seq       TRUE\nPuBu             9      seq       TRUE\nPuBuGn           9      seq       TRUE\nPuRd             9      seq       TRUE\nPurples          9      seq       TRUE\nRdPu             9      seq       TRUE\nReds             9      seq       TRUE\nYlGn             9      seq       TRUE\nYlGnBu           9      seq       TRUE\nYlOrBr           9      seq       TRUE\nYlOrRd           9      seq       TRUE\n\n\nIt is very helpful to look at the different kinds of data palettes available and I’ll show you how to use them below when we color in the states based upon population size at the end of this document.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "narrative_classic.html#annotations",
    "href": "narrative_classic.html#annotations",
    "title": "6  Data Visualization",
    "section": "6.4 Annotations",
    "text": "6.4 Annotations\nYou can easily add text onto a graph using the text() function. Here is the correlation between the sepal length and width (the function cor.test() does the statistical test).\n\ncor &lt;- cor.test( iris$Sepal.Length, iris$Sepal.Width )\ncor\n\n\n    Pearson's product-moment correlation\n\ndata:  iris$Sepal.Length and iris$Sepal.Width\nt = -1.4403, df = 148, p-value = 0.1519\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.27269325  0.04351158\nsample estimates:\n       cor \n-0.1175698 \n\n\nWe can put the correlation and the p-value on the plot\n\ncor.text &lt;- paste( \"r = \", format( cor$estimate, digits=4), \"; P = \", format( cor$p.value, digits=4 ), sep=\"\" ) \ncor.text\n\n[1] \"r = -0.1176; P = 0.1519\"\n\n\nThe we can the overlay this onto an existing plot. For the text() function, we need to give the x- and y- coordinates where you want it put onto the coordinate space of the existing graph.\n\nplot( y ~ x , \n      col=colors, \n      pch=20, \n      bty=\"n\", \n      xlab=\"Sepal Length\", ylab=\"Sepal Width\")\ntext( 7.4, 4.2, cor.text )",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "narrative_ggplot.html",
    "href": "narrative_ggplot.html",
    "title": "7  ggplot2 Graphics",
    "section": "",
    "text": "7.1 Basic ggplot\nIn base R, the graphics are generally produced by adding a lot of optional arguments to a single function such as plot() or barplot() or boxplot(). We can get some kinds of overlays using text() or points() or lines() but there is not a cohesive framework for setting this up. For even moderately complex graphical display, these approaches become unwieldy when we have to cram all that information into extra optional arguments.\nConsider the graph below whose data are from a 2011 article in The Economist measuring human development and perception of corruption for 173 countries (Figure 7.1). Both the amount of data and the way in which the data are displayed (physically and aesthetically) are somewhat complex.\nThis graphic is constructed from several additive components1 including:\nTruth be told (and you can look at the RMD of this file to verify), this one graphic required 42 relatively terse lines of code to construct! If all of that code was stuffed into the optional arguments for a few functions, I think I would go mad.\nLuckily for us, there are people who spend a lot of time working on these issues and thinking about how to best help us effectively display data. One of these individuals was Leland Wilkinson, whose book The Grammar of Graphics defined just such a system.\nThis philosophy has been inserted into the R Ecosystem by Hadley Wickham in the ggplot2 library, which is descbribed as:\nThroughout the majority of this course, we will be using this library and this approach for all but the most trivial of graphical displays.\nAs outlined above, the basis of this appraoch is an additive (and iterative) process of creating a graphic. This all starts with the data. For our purposes, we will use the same iris data.frame as in the previous section on base graphics.\nsummary( iris )\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50\nWe start building a graphic using the ggplot() function and passing it the data.frame object. This will initialize the graphic, though it will not plot anything.\nlibrary(ggplot2)\n\nggplot( iris )\nNext, we need to tell the plot which variables it will be using from the data.frame. For simplicity, we do not need to make special data objects with just the variables we want to plot, we can pass around the whole data.frame object and just indicate to ggplot which ones we want to use by specifying the aesthetics to be used.\nggplot( iris , aes( x=Sepal.Length ) )\nAt this point, there is enough information to make an axis in the graph because the underlying data has been identified. What has not been specified to date is the way in which we want to represent the data. To do this, we add geometries to the graph. In this case, I’m going to add a histogram\nggplot( iris, aes(x=Sepal.Length) ) + geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\nNow we have a base graph!",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>`ggplot2` Graphics</span>"
    ]
  },
  {
    "objectID": "narrative_ggplot.html#basic-ggplot",
    "href": "narrative_ggplot.html#basic-ggplot",
    "title": "7  ggplot2 Graphics",
    "section": "",
    "text": "The iris data",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>`ggplot2` Graphics</span>"
    ]
  },
  {
    "objectID": "narrative_ggplot.html#aestheics-and-scope",
    "href": "narrative_ggplot.html#aestheics-and-scope",
    "title": "7  ggplot2 Graphics",
    "section": "7.2 Aestheics and Scope",
    "text": "7.2 Aestheics and Scope\nThe location of the data and the aes() determines the scope of the assignment. What I mean by this is:\n\nIf the data and aes() is in the the ggplot() function, then everything in the whole plot inherits that assignment.\nIf you put them in one or more of the components you add to ggplot() then the they are localized to only those layers.\n\nSo the following statements are all identical for this most basic of plots.\n\nggplot( iris, aes(x=Sepal.Length) ) + geom_histogram()\nggplot( iris ) + geom_historgram( aes(x=Sepal.Length) )\nggplot() + geom_histogram( aes(x=Sepal.Length), data=iris)\n\n\nIn the first case, the geom_histogram() inherits both data and aesthetics from ggplot().\n\nIn the second one, it inherits only the data but has it’s own specification for aesthetics.\nIn the last one, ggplot() only specifies the presence of a graph and all the data and aesthetics are localized within geom_histogram() function.\n\nWhere this becomes important is when we want to make more complicated graphics like the one above. The data that has the country CDI and HDI also has the names of the countries. However, only a subset of the country names are plot. This is because both the geometric layer and the text layer that has the names are using different data.frame objects.\nHere is a more simplistic example where I overlay a density plot (as a red line) on top of the histogram.\n\nggplot( iris, aes(x=Sepal.Length) ) + geom_histogram() + geom_density( col=\"red\")\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\nBoth the geom_histogram and the geom_density use the same data and same specification for how to deal with the y-axis. However, the density is depicted as a frequency on the y-axis whereas the histogram uses counts. Also notice how the col=\"red\" is localized just for the geom_density() layer.\nWe can override the way in which geom_histogram uses the y-axis by changing the aesthetics for that particular geometric layer. Here, I’m goint to add another aes() just within the geom_histogram() function and have it treat y as the density rather than the count (yes that is two periods before and after the word density).\n\nggplot( iris, aes(x=Sepal.Length) ) + geom_histogram(aes(y=..density..)) + geom_density( col=\"red\" )\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\nBy default, everything inside the ggplot() function call is inherited by all the remaining components unless it is specifically overridden. Here is a more pedantic version where only the raw data.frame is in the ggplot and the rest is in each of the geometric layers.\n\nggplot( iris ) + \n  geom_histogram( aes(x=Sepal.Length, y=..density..) ) + \n  geom_density( aes(x=Sepal.Length), col=\"red\", lwd=2)\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>`ggplot2` Graphics</span>"
    ]
  },
  {
    "objectID": "narrative_ggplot.html#labels-titles",
    "href": "narrative_ggplot.html#labels-titles",
    "title": "7  ggplot2 Graphics",
    "section": "7.3 Labels & Titles",
    "text": "7.3 Labels & Titles\nJust like we added geometric layers to the plot to make histograms and densities, we do the same for labels and titles.\n\nggplot( iris,  aes(x=Sepal.Length) ) + \n  geom_histogram( aes(y=..density..), bins = 10, fill=\"lightgray\", col=\"darkgrey\" ) + \n  geom_density( col=\"red\", lwd=1.5) + \n  xlab(\"Length\") + ylab(\"Density\") + \n  ggtitle(\"Sepal Lengths for Three Iris Species\")",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>`ggplot2` Graphics</span>"
    ]
  },
  {
    "objectID": "narrative_ggplot.html#scatter-plots",
    "href": "narrative_ggplot.html#scatter-plots",
    "title": "7  ggplot2 Graphics",
    "section": "7.4 Scatter Plots",
    "text": "7.4 Scatter Plots\nWith two columns of data, we can make the old scatter plot using the geom_point() function.\n\nggplot( iris, aes(x=Sepal.Length, y=Sepal.Width) ) + geom_point( col=\"purple\") \n\n\n\n\n\n\n\n\nIn this plot, we are hiding some of the information by having all the points be the same color and shape. We could have a geom_point for each species as follows:\n\nggplot(  ) + \n  geom_point( aes( x = Sepal.Length, y = Sepal.Width), data=iris[ 1:50,], col=\"red\") + \n  geom_point( aes( x = Sepal.Length, y = Sepal.Width), data=iris[ 51:100,], col=\"yellow\" ) + \n  geom_point( aes( x = Sepal.Length, y = Sepal.Width), data=iris[ iris$Species == \"virginica\", ], col=\"darkgreen\" ) \n\n\n\n\n\n\n\n\nBut that is a lot of typing. In cases like this, where there is a an actual column of data that we want to use to change the appearance (e.g., in this case the Species column), we can put this within the aes() directly and ggplot() will handle the specifics for you. Anything we do to reduce the amount of typing we must do is going to help us be more accurate analysts.\n\nggplot( iris, aes( x = Sepal.Length, y = Sepal.Width, col=Species) ) + geom_point()\n\n\n\n\n\n\n\n\n\n7.4.1 In or Out of aes()\nNotice in the last graph I put the name of the data column in the aesthetic but have the color (col) within the aes() function call in the graph before that, I put color outside of the aes() in the geom_point() function. What gives? Here is a simple rule.\n\nIf information from within the data.frame is needed to customize the display of data then it must be designated within the aes(), whereas if the display of the data is to be applied to the entire geometric layer, it is specified outside of the aes() call.\n\nHere is an example, where I have the color of the shapes determined by a value in the data.frame but have the shape2 applied to all the points, independent of any data in the data.frame.\n\nggplot( iris ) + geom_point(aes( x = Sepal.Length, y = Sepal.Width, col=Species), shape=5)\n\n\n\n\n\n\n\n\nWe can build these things in an iterative fashion making things easier to read. In what follows I will use the basic plot from above but assign it to the variable p as I add things to it. It can be as iterative as you like and you can add a bunch of stuff and wait until the end to display it.\n\np &lt;- ggplot( iris ) \np &lt;- p + geom_point(aes( x = Sepal.Length, y = Sepal.Width, col=Species, shape=Species), size=3, alpha=0.75 ) \np &lt;- p + xlab(\"Sepal Length\") \np &lt;- p + ylab(\"Sepal Width\")\n\nThe overall class of the plot varible is\n\nclass(p)\n\n[1] \"ggplot2::ggplot\" \"ggplot\"          \"ggplot2::gg\"     \"S7_object\"      \n[5] \"gg\"             \n\n\nAnd there is no plot output until we display it specifically.\n\np",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>`ggplot2` Graphics</span>"
    ]
  },
  {
    "objectID": "narrative_ggplot.html#themes",
    "href": "narrative_ggplot.html#themes",
    "title": "7  ggplot2 Graphics",
    "section": "7.5 Themes",
    "text": "7.5 Themes\nThe overall coloration of the plot is determined by the theme.\n\np + theme_bw()\n\n\n\n\n\n\n\n\n\np + theme_dark()\n\n\n\n\n\n\n\n\n\np + theme_minimal()\n\n\n\n\n\n\n\n\n\np + theme_linedraw()\n\n\n\n\n\n\n\n\n\np + theme_void()\n\n\n\n\n\n\n\n\nYou can even define your own themes to customize all the text and lines.\nOne thing that I like to do is to specify a default theme for all my plots. You can accomplish this using theme_set() and from this point forward, this theme will be used as the default (again, we need to try as hard as possible to minimzie the amount of typing we do to minimize the amount of mistakes we make).\n\ntheme_set( theme_bw() )",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>`ggplot2` Graphics</span>"
    ]
  },
  {
    "objectID": "narrative_ggplot.html#boxplots",
    "href": "narrative_ggplot.html#boxplots",
    "title": "7  ggplot2 Graphics",
    "section": "7.6 Boxplots",
    "text": "7.6 Boxplots\n\nggplot( iris, aes( x = Sepal.Length) ) + geom_boxplot( notch=TRUE )\n\n\n\n\n\n\n\n\n\nggplot( iris, aes(x=Species, y=Sepal.Length) )  + geom_boxplot( notch=TRUE )",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>`ggplot2` Graphics</span>"
    ]
  },
  {
    "objectID": "narrative_ggplot.html#overlays",
    "href": "narrative_ggplot.html#overlays",
    "title": "7  ggplot2 Graphics",
    "section": "7.7 Overlays",
    "text": "7.7 Overlays\nJust like in the previous\n\np &lt;- ggplot( iris, aes(Sepal.Length, Sepal.Width) ) + \n  geom_point(col=\"red\") + \n  xlab(\"Sepal Length\") + \n  ylab(\"Sepal Width\")\n\nThe order by which you add the components to the ggplot() will determine the order of the layers from bottom to top—the. Layers added earlier will be covered by content in layers that are added later. Compare the following plot that takes the length and width of the sepals and overlays a linear regression line over the top.\n\np + geom_point(col=\"red\") + \n  stat_smooth( formula = y ~ x, method=\"lm\", alpha=1.0)\n\n\n\n\n\n\n\n\nCompare that plot to the one below. Notice how puting stat_smooth() in front of the call to geom_point() layes the regression smoothing line and error zone underneath the points.\n\np + stat_smooth(formula = y ~ x, method=\"lm\", alpha=1.0) + \n  geom_point(col=\"red\")",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>`ggplot2` Graphics</span>"
    ]
  },
  {
    "objectID": "narrative_ggplot.html#labeling",
    "href": "narrative_ggplot.html#labeling",
    "title": "7  ggplot2 Graphics",
    "section": "7.8 Labeling",
    "text": "7.8 Labeling\nWe can create two kinds of annotations, text on the raw graph and text associated with some of the points. Labels of the first kind can be added direclty by placing raw data inside the aes() function.\nI’ll start by taking the correlation between sepal width and length.\n\ncor &lt;- cor.test( iris$Sepal.Length, iris$Sepal.Width )\ncor\n\n\n    Pearson's product-moment correlation\n\ndata:  iris$Sepal.Length and iris$Sepal.Width\nt = -1.4403, df = 148, p-value = 0.1519\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.27269325  0.04351158\nsample estimates:\n       cor \n-0.1175698 \n\n\nAnd then grab the raw data from it and make a message.\n\ncor.text &lt;- paste( \"r = \", format( cor$estimate, digits=4), \"; P = \", format( cor$p.value, digits=4 ), sep=\"\" ) \ncor.text\n\n[1] \"r = -0.1176; P = 0.1519\"\n\n\nThat I’ll stick onto the graph directly\n\np + geom_text( aes(x=7.25, y=4.25, label=cor.text))\n\nWarning in geom_text(aes(x = 7.25, y = 4.25, label = cor.text)): All aesthetics have length 1, but the data has 150 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\nAlternatively, we may want to label specific points. Here I find the mean values for each species.\n\nmean_Length &lt;- by( iris$Sepal.Length, iris$Species, mean, simplify = TRUE)\nmean_Width &lt;- by( iris$Sepal.Width, iris$Species, mean, simplify = TRUE)\nmean_Values &lt;- data.frame(  Species = levels( iris$Species), \n                            Sepal.Length = as.numeric( mean_Length ), \n                            Sepal.Width = as.numeric( mean_Width ) ) \nmean_Values\n\n     Species Sepal.Length Sepal.Width\n1     setosa        5.006       3.428\n2 versicolor        5.936       2.770\n3  virginica        6.588       2.974\n\n\nTo plot and label these mean values, I’m going to use two steps. First, since I named the columns of the new data.frame the same as before, we can just inherit the aes() but substitute in this new data.frame and add label=Species to the the aesthetics.\n\np + geom_text( data=mean_Values, aes(label=Species) )\n\n\n\n\n\n\n\n\nBut that is a bit messy. Here is a slick helper library for that that will try to minimize the overlap.\n\nlibrary( ggrepel ) \np + geom_label_repel( data=mean_Values, aes(label=Species) )\n\n\n\n\n\n\n\n\nSlick.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>`ggplot2` Graphics</span>"
    ]
  },
  {
    "objectID": "narrative_ggplot.html#questions",
    "href": "narrative_ggplot.html#questions",
    "title": "7  ggplot2 Graphics",
    "section": "7.9 Questions",
    "text": "7.9 Questions\nIf you have any questions for me specifically on this topic, please post as an Issue in your repository, otherwise consider posting to the discussion board on Canvas.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>`ggplot2` Graphics</span>"
    ]
  },
  {
    "objectID": "narrative_ggplot.html#footnotes",
    "href": "narrative_ggplot.html#footnotes",
    "title": "7  ggplot2 Graphics",
    "section": "",
    "text": "Literally, we add these toghter using the plus ‘+’ sign just like we were going to develop an equation.↩︎\nThe shapes are the same as the pch offerings covered in the lecture on graphing using Base R routines here.↩︎",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>`ggplot2` Graphics</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "8  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "narrative_points.html",
    "href": "narrative_points.html",
    "title": "8  Spatial Point Data",
    "section": "",
    "text": "8.1 Learning Objectives\nLet’s start by loading in some of the libraries we’ll be using for this exercise.\nThis topics is the first",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Spatial Point Data</span>"
    ]
  },
  {
    "objectID": "narrative_points.html#learning-objectives",
    "href": "narrative_points.html#learning-objectives",
    "title": "8  Spatial Point Data",
    "section": "",
    "text": "Describe the importance of Ellipsoids & Datum in spatial data.\nUse both sf & ggplot in visualizing point data.\nBe able to transform point data from one projection to another.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Spatial Point Data</span>"
    ]
  },
  {
    "objectID": "narrative_points.html#ellipsoids",
    "href": "narrative_points.html#ellipsoids",
    "title": "8  Spatial Point Data",
    "section": "8.2 Ellipsoids",
    "text": "8.2 Ellipsoids\nUnless you are in PHYS 101, the earth is not a perfect sphere (😉). It is an irregularly shaped object that we need to be able to characterize if we are going to develop a system of placing points onto it and doing things such as measuring distance, finding watersheds, or defining boundaries.\nThere has been a long history of ellipsoid research, all of which has been sought to increase our ability to map and move across the earth. The following table gives some historical and contemporary ellipsoids.\n\n\n\n\n\n\n\n\n\nEllipsoid\nEquatorial Radius (m)\nPolar Radius (m)\nUsed\n\n\n\n\nMaupertuis (1738)\n6,397,300\n6,363,806.283\nFrance\n\n\nPlessis (1817)\n6,376,523.0\n6,355,862.9333\nFrance\n\n\nEverest (1830)\n6,377,299.365\n6,356,098.359\nIndia\n\n\nEverest 1830 Modified (1967)\n6,377,304.063\n6,356,103.0390\nWest Malaysia & Singapore\n\n\nEverest 1830 (1967 Definition)\n6,377,298.556\n6,356,097.550\nBrunei & East Malaysia\n\n\nAiry (1830)\n6,377,563.396\n6,356,256.909\nBritain\n\n\nBessel (1841)\n6,377,397.155\n6,356,078.963\nEurope, Japan\n\n\nClarke (1866)\n6,378,206.4\n6,356,583.8\nNorth America\n\n\nClarke (1878)\n6,378,190\n6,356,456\nNorth America\n\n\nClarke (1880)\n6,378,249.145\n6,356,514.870\nFrance, Africa\n\n\nHelmert (1906)\n6,378,200\n6,356,818.17\nEgypt\n\n\nHayford (1910)\n6,378,388\n6,356,911.946\nUSA\n\n\nInternational (1924)\n6,378,388\n6,356,911.946\nEurope\n\n\nKrassovsky (1940)\n6,378,245\n6,356,863.019\nUSSR, Russia, Romania\n\n\nWGS66 (1966)\n6,378,145\n6,356,759.769\nUSA/DoD\n\n\nAustralian National (1966)\n6,378,160\n6,356,774.719\nAustralia\n\n\nNew International (1967)\n6,378,157.5\n6,356,772.2\n\n\n\nGRS-67 (1967)\n6,378,160\n6,356,774.516\n\n\n\nSouth American (1969)\n6,378,160\n6,356,774.719\nSouth America\n\n\nWGS-72 (1972)\n6,378,135\n6,356,750.52\nUSA/DoD\n\n\nGRS-80 (1979)\n6,378,137\n6,356,752.3141\nGlobal ITRS\n\n\nWGS-84 (1984)\n6,378,137\n6,356,752.3142\nGlobal GPS\n\n\nIERS (1989)\n6,378,136\n6,356,751.302\n\n\n\nIERS (2003)\n6,378,136.6\n6,356,751.9\n\n\n\n\nThe most common ones you will probably run across include GRS80/NAD83 (derived from satellite measurements of the distance of the surface to the core of the planet ) and WGS-84 (an ellipsoid based upon GPS).\n\n8.2.1 Example Data\nTo examine the differences between ellipsoids, let’s load in some data first. Here are some point data that can be interpreted as polygons and represent the lower 48 states of the US.\n\nstates &lt;- map_data(\"state\")\nhead( states )\n\n       long      lat group order  region subregion\n1 -87.46201 30.38968     1     1 alabama      &lt;NA&gt;\n2 -87.48493 30.37249     1     2 alabama      &lt;NA&gt;\n3 -87.52503 30.37249     1     3 alabama      &lt;NA&gt;\n4 -87.53076 30.33239     1     4 alabama      &lt;NA&gt;\n5 -87.57087 30.32665     1     5 alabama      &lt;NA&gt;\n6 -87.58806 30.32665     1     6 alabama      &lt;NA&gt;\n\n\nEach row is a point that is associated with a group (in this case the state) and is plot in a specific order (to make the outline of the state). There are 15,537 points required to make the plot, with the following 49 regions.\n\nunique( states$region )\n\n [1] \"alabama\"              \"arizona\"              \"arkansas\"            \n [4] \"california\"           \"colorado\"             \"connecticut\"         \n [7] \"delaware\"             \"district of columbia\" \"florida\"             \n[10] \"georgia\"              \"idaho\"                \"illinois\"            \n[13] \"indiana\"              \"iowa\"                 \"kansas\"              \n[16] \"kentucky\"             \"louisiana\"            \"maine\"               \n[19] \"maryland\"             \"massachusetts\"        \"michigan\"            \n[22] \"minnesota\"            \"mississippi\"          \"missouri\"            \n[25] \"montana\"              \"nebraska\"             \"nevada\"              \n[28] \"new hampshire\"        \"new jersey\"           \"new mexico\"          \n[31] \"new york\"             \"north carolina\"       \"north dakota\"        \n[34] \"ohio\"                 \"oklahoma\"             \"oregon\"              \n[37] \"pennsylvania\"         \"rhode island\"         \"south carolina\"      \n[40] \"south dakota\"         \"tennessee\"            \"texas\"               \n[43] \"utah\"                 \"vermont\"              \"virginia\"            \n[46] \"washington\"           \"west virginia\"        \"wisconsin\"           \n[49] \"wyoming\"             \n\n\nFortunately for us, our old friend ggplot has a bit of magic that can do this kind of plotting for us.\n\nlibrary( ggplot2 )\nggplot( states, aes( x = long, \n                     y = lat,\n                     group = group ) ) + \n  geom_polygon( fill = \"lightgray\", \n                color = \"black\", \n                lwd = 0.25) + \n  theme_void() -&gt; p\n\n\n\n8.2.2 Azimuth Projections\nAn Azimuth Projection is one that is formed by a 2-dimensional plane that is tangential to the surface of the earth at example one point. This point may be polar (north or south pole) or oblique (e.g., over Richmond, Virginia).\n\n\n\n\nAzequidistant\n\n\n\nWe can apply different ellipsoids to the map when we plot it by adjusting the coordinate space it is plot within using the coord_map() modification. For a whole list of available projections, see ?mapproject.\n\np + coord_map( \"azequalarea\")\n\n\n\n\n\n\n\n\n\n\n8.2.3 Cylindrical Projection\nA cylindrical projection is one where a cylinder is wrapped around the earth creating straight lines for all parallel away from the equator.\n\n\n\n\nCylindrical Projection\n\n\n\n\np + coord_map(\"cylindrical\")\n\n\n\n\n\n\n\n\n\n\n8.2.4 Conic Projections\nConic projections are symmetric around the prime meridian and all parallels are segments of conecntric circles.\n\n\n\n\nConic Projection\n\n\n\n\np + coord_map( \"conic\", lat0 = 30)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Spatial Point Data</span>"
    ]
  },
  {
    "objectID": "narrative_points.html#datum",
    "href": "narrative_points.html#datum",
    "title": "8  Spatial Point Data",
    "section": "8.3 Datum",
    "text": "8.3 Datum\nOnce we have an ellipsoid model to work with we must define a DATUM type that will represent the coordiante system used. Two common DATUM types include:\n\nLongitude & Latitude - The East/West & North/South position on the surface of the earth.\n\nPrime Meridian (0° Longitude) passes thorugh the Royal Observatory in Greenwich England, with positive values of longitude to the east and negative to the west.\nEquator (0° Latitude) and is defined as the point on the planet where both northern and southern hemisphers have equal amounts of day and night at the equinox (Sept. 21 & March 21).\nRichmond, Virginia: 37.533333 Latitude, -77.466667 Longitude\n\nUniversal Trans Mercator - A division of the earth into 60 zones (~6°longitude each, labeled 01 - 60) and 20 bands each of which is ~8° latitude (labeled C-X excluding I & O with A & B dividing up Antartica). See image here.\n\nCoordinates include Zone & band designation as well as coordinates in Easting and Northing (planar coordinates within the zone) measured in meters.\nRichmond, Virginia: 18S 282051 4156899\n\n\n\n\n\n\n⚠️\n\n\n \n\n\nYou must set both the ellipsoid and datum to be EXACTLY THE SAME for all of your data before you can do any work with it. If they are not on the same lumpy bumpy planet or in the same coordinate system, you will be screwed (that is a technical term).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Spatial Point Data</span>"
    ]
  },
  {
    "objectID": "narrative_points.html#sf-objects",
    "href": "narrative_points.html#sf-objects",
    "title": "8  Spatial Point Data",
    "section": "10.1 sf Objects",
    "text": "10.1 sf Objects\nSimple Features (hereafter abbreviated as sf) are an open standard developed by the Open Geospatial Consortium (OGC). They define the following basic types:\n\nPOINT\n\nLINESTRING\nPOLYGON\n\nMULTIPOINT\nMULTILINESTRING\nMULTIPOLYGON\nGEOMETRYCOLLECTION\n\nEach of these basic types can be represented within a single column of a data.frame. To do this, we need to tell the conversion function st_as_sf() which columns to consider as the datum and which ellipsoid to use.\n\nlibrary( sf )\ndata |&gt;\n  st_as_sf( coords=c(\"Longitude\",\"Latitude\"),\n            crs = 4326 ) -&gt; data\nhead( data )\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -110.951 ymin: 23.2855 xmax: -109.8507 ymax: 24.21441\nGeodetic CRS:  WGS 84\n# A tibble: 6 × 8\n  Site  Males Females Suitability MFRatio GenVarArapat GenVarEuphli\n  &lt;chr&gt; &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 Aqu      12       9       0.722   1.33         0.120       0.0968\n2 73       11       5       0.146   2.2          0.137       0.253 \n3 157      26      30       0.881   0.867        0.150       0.191 \n4 153      35      41       0.732   0.854        0.333       0.276 \n5 163      21      21       0.433   1            0.298       0.338 \n6 48       18      27       0.620   0.667        0.115       0.213 \n# ℹ 1 more variable: geometry &lt;POINT [°]&gt;\n\n\nThis conversion to an sf object adds attributes to the data.frame and tibble object.\n\nclass( data )\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nThis additional sf attributes gives it more qualities such as a bounding box (e.g., the area within which all the poitns exist)\n\nst_bbox( data )\n\n      xmin       ymin       xmax       ymax \n-114.29353   23.28550 -109.32700   29.32541 \n\n\nDistances between objects.\n\nst_distance( data[1,], data[2,])\n\nUnits: [m]\n        [,1]\n[1,] 84376.8\n\n\nAs well as complex geospatial operations such as finding the convex hull (the minimal area containing all poitns).\n\ndata |&gt;\n  st_union() |&gt;\n  st_convex_hull() -&gt; hull\nhull\n\nGeometry set for 1 feature \nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -114.2935 ymin: 23.2855 xmax: -109.327 ymax: 29.32541\nGeodetic CRS:  WGS 84\n\n\nPOLYGON ((-114.2935 29.32541, -113.9914 28.6605...\n\n\nthe center of the all the points.\n\nhull |&gt;\n  st_centroid()\n\nGeometry set for 1 feature \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -111.3417 ymin: 26.37741 xmax: -111.3417 ymax: 26.37741\nGeodetic CRS:  WGS 84\n\n\nPOINT (-111.3417 26.37741)\n\n\nand the area enclosed by all the points (for various units).\n\nlibrary( units )\n\nudunits database from /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/units/share/udunits/udunits2.xml\n\nhull |&gt;\n  st_area() |&gt;\n  set_units( km^2 )\n\n122130.5 [km^2]\n\n\n\n10.1.1 Reprojecting\nIn addition to the operations above, properly created sf objects can easily be projected from one CRS into another (epsg 6372 is a common projection covering Mexico based upon the GRS80 elipsoid and the latest ITRF2008 datum standard based on the meter)4.\n\ndata |&gt;\n  st_transform( 6372 ) |&gt;\n  st_bbox()\n\n   xmin    ymin    xmax    ymax \n1307745 1274010 1773676 1968473 \n\n\nAgain, do this first to all your data to make sure it is put into a proper projection (and most of your headaches will disappear).\n\n\n10.1.2 Plotting sf Objects\nAnalogous to the duality between built-in R plotting and ggplot approaches, we can use either of these frameworks to plot sf objects.\nAs built-in objects, a sf data set that has a geometry coordinate is intrinsically linked to all the other data columns. If we plot the entire data frame, we see that for each non-geometry data column, we create an individual plot.\n\nplot( data )\n\n\n\n\n\n\n\n\nThe data with the data.frame can be accessed as normal.\n\nplot( data$Suitability )\n\n\n\n\n\n\n\n\nBut if we plot it using the square brackets and names of dat columns, we can link the geometry column to it and plot it as a spatial representation of those data (and adorn it with the normal plot() upgrades accordingly).\n\nplot( data[\"Suitability\"], pch=16, cex=2)\n\n\n\n\n\n\n\n\nPerhaps not surprisingly, ggplot() also works the same way, however, the geospatial coordiantes for the plot aare taken care of using geom_sf() and you are left with definining which of the data columns you want to put into the plot as a component of the aes() definition.\n\nggplot( data, aes(color=Suitability) ) + \n  geom_sf( )\n\n\n\n\n\n\n\n\nIt works the same ways for lables.\n\nggplot( data ) + \n  geom_sf_text( aes(label=Site) ) + \n  theme_void() + \n  coord_map()\n\nWarning in st_point_on_surface.sfc(sf::st_zm(x)): st_point_on_surface may not\ngive correct results for longitude/latitude data",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Spatial Point Data</span>"
    ]
  },
  {
    "objectID": "narrative_points.html#footnotes",
    "href": "narrative_points.html#footnotes",
    "title": "8  Spatial Point Data",
    "section": "",
    "text": "Tobler, W. R. 1970. Economic Geography, 46, 234–240.↩︎\nTranslation from one CRS to another in all GIS software is handled by the open source proj.org library.↩︎\nThe EPSG standard was originally created in 1985 by the https://en.wikipedia.org/wiki/European_Petroleum_Survey_Group and made public in 1993.↩︎\nThis standard is defined by Sistema Nacional de Información Estadística y Geográfica.↩︎\nThis is because if we use the normal procedures, we mess up the order in which everything is plot in geom_polygon(), try it and see.↩︎",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Spatial Point Data</span>"
    ]
  }
]